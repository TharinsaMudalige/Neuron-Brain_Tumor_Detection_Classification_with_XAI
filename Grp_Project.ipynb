{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Image-Preprocesing/Grp_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow 2.18.0 and segmentation-models 1.0.1\n",
        "!pip install --upgrade tensorflow==2.18.0 segmentation-models==1.0.1\n",
        "\n",
        "# Uninstall and reinstall protobuf to force version 3.20.3\n",
        "!pip uninstall -y protobuf\n",
        "!pip install protobuf==3.20.3\n",
        "\n",
        "# Install kagglehub (if not already installed)\n",
        "!pip install kagglehub\n",
        "\n",
        "# Set environment variables BEFORE importing other packages\n",
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
        "\n",
        "# Import necessary libraries and mount Google Drive (if needed)\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "import tensorflow.keras as keras\n",
        "print(\"tf.keras is available.\")\n",
        "\n",
        "import segmentation_models as sm\n",
        "import glob\n",
        "import cv2\n",
        "import nibabel as nib\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DJgvGe86E-O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset From Kaggle"
      ],
      "metadata": {
        "id": "YA7hvlH7FiW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the BraTS2020 dataset (training+validation) from Kaggle\n",
        "DATASET_NAME = \"awsaf49/brats20-dataset-training-validation\"\n",
        "dataset_path = kagglehub.dataset_download(DATASET_NAME)\n",
        "print(\"Dataset downloaded to:\", dataset_path)\n",
        "\n",
        "# Inspect the downloaded folder structure\n",
        "!ls -lh \"{dataset_path}\"\n",
        "\n",
        "# Copy the extracted TrainingData folder (which contains the patient subdirectories)\n",
        "!mkdir -p /content/brats_data\n",
        "!cp -r \"{dataset_path}/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\" /content/brats_data/\n",
        "\n",
        "# Set the training data directory to the copied folder\n",
        "BRATS_DATA_DIR = \"/content/brats_data/MICCAI_BraTS2020_TrainingData\"\n",
        "!ls -lh \"{BRATS_DATA_DIR}\""
      ],
      "metadata": {
        "id": "HUYP9WbrFLlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Functions"
      ],
      "metadata": {
        "id": "_aAWqNKpF9co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_slices(nifti_path):\n",
        "    \"\"\"Load a 3D .nii volume and return a list of normalized 2D slices.\"\"\"\n",
        "    nii_img = nib.load(nifti_path)\n",
        "    data = nii_img.get_fdata()  # Shape: (H, W, Depth)\n",
        "    slices = []\n",
        "    for i in range(data.shape[2]):  # Iterate over axial slices\n",
        "        slice_data = data[:, :, i]\n",
        "        # Normalize to [0, 1]\n",
        "        slice_norm = (slice_data - np.min(slice_data)) / (np.max(slice_data) - np.min(slice_data) + 1e-8)\n",
        "        # Resize to 256x256\n",
        "        slice_resized = cv2.resize(slice_norm, (256, 256))\n",
        "        slices.append(slice_resized)\n",
        "    return slices\n",
        "\n",
        "def extract_mask_slices(nifti_path):\n",
        "    \"\"\"Load a 3D mask (.nii) and return 2D binary slices.\"\"\"\n",
        "    nii_mask = nib.load(nifti_path)\n",
        "    data = nii_mask.get_fdata()\n",
        "    slices = []\n",
        "    for i in range(data.shape[2]):\n",
        "        slice_data = data[:, :, i]\n",
        "        # Convert multi-class labels to binary: tumor vs. background\n",
        "        binary_slice = (slice_data > 0).astype(np.float32)\n",
        "        slice_resized = cv2.resize(binary_slice, (256, 256))\n",
        "        slices.append(slice_resized)\n",
        "    return slices\n",
        "\n",
        "def process_brats_data(brats_dir, save_dir=\"brats_slices\"):\n",
        "    \"\"\"\n",
        "    Processes BraTS data from a directory containing patient subdirectories.\n",
        "    Each patient directory should contain files like *_flair.nii and *_seg.nii.\n",
        "    save_dir: Folder where 2D slices will be stored (subfolders \"images\" and \"masks\" will be created).\n",
        "    \"\"\"\n",
        "    images_save_dir = os.path.join(save_dir, \"images\")\n",
        "    masks_save_dir  = os.path.join(save_dir, \"masks\")\n",
        "    os.makedirs(images_save_dir, exist_ok=True)\n",
        "    os.makedirs(masks_save_dir, exist_ok=True)\n",
        "\n",
        "    # Get all patient subdirectories in brats_dir (e.g., BraTS20_Training_314, etc.)\n",
        "    patient_dirs = glob.glob(os.path.join(brats_dir, \"BraTS20_Training_*\"))\n",
        "    slice_count = 0\n",
        "\n",
        "    for patient_dir in patient_dirs:\n",
        "        print(\"Processing patient:\", patient_dir)\n",
        "        # Look for flair and seg files within each patient directory\n",
        "        flair_files = glob.glob(os.path.join(patient_dir, \"*_flair.nii\"))\n",
        "        seg_files   = glob.glob(os.path.join(patient_dir, \"*_seg.nii\"))\n",
        "        if len(flair_files) == 0 or len(seg_files) == 0:\n",
        "            print(\"No flair or seg file found in\", patient_dir)\n",
        "            continue\n",
        "\n",
        "        flair_file = flair_files[0]\n",
        "        seg_file = seg_files[0]\n",
        "\n",
        "        flair_slices = extract_slices(flair_file)\n",
        "        seg_slices = extract_mask_slices(seg_file)\n",
        "\n",
        "        n_slices = min(len(flair_slices), len(seg_slices))\n",
        "        print(\"Found\", n_slices, \"slices in\", flair_file)\n",
        "\n",
        "        for i in range(n_slices):\n",
        "            # Convert flair slice to RGB by stacking the grayscale image into 3 channels\n",
        "            img_gray = (flair_slices[i] * 255).astype(np.uint8)\n",
        "            img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
        "            msk = (seg_slices[i] * 255).astype(np.uint8)\n",
        "\n",
        "            base_name = os.path.basename(flair_file).replace(\"_flair.nii\", \"\")\n",
        "            img_filename = os.path.join(images_save_dir, f\"{base_name}_slice_{i}.png\")\n",
        "            msk_filename = os.path.join(masks_save_dir, f\"{base_name}_slice_{i}.png\")\n",
        "\n",
        "            cv2.imwrite(img_filename, img_rgb)\n",
        "            cv2.imwrite(msk_filename, msk)\n",
        "            slice_count += 1\n",
        "\n",
        "    print(f\"Total 2D slices saved: {slice_count}\")\n",
        "\n",
        "# Run the processing function\n",
        "process_brats_data(BRATS_DATA_DIR, save_dir=\"brats_slices\")\n",
        "\n",
        "# Verify that PNG files were created\n",
        "!ls -lh brats_slices/images\n",
        "!ls -lh brats_slices/masks"
      ],
      "metadata": {
        "id": "Al5TkxXLF8LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "EWnTspl6GOf5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M4Wb8niNGN6q"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fVqyoQHbaPpjvI09Xrt43SbwgANTTeNc",
      "authorship_tag": "ABX9TyMRAkyaX6Rc4HB3IzshxTLT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}