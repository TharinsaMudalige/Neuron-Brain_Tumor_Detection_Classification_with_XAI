{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Image-Preprocesing/Grp_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install TensorFlow 2.18.0 and segmentation-models 1.0.1\n",
        "!pip install --upgrade tensorflow==2.18.0 segmentation-models==1.0.1\n",
        "\n",
        "# Uninstall and reinstall protobuf to force version 3.20.3\n",
        "!pip uninstall -y protobuf\n",
        "!pip install protobuf==3.20.3\n",
        "\n",
        "# Install kagglehub (if not already installed)\n",
        "!pip install kagglehub\n",
        "\n",
        "# Set environment variables BEFORE importing other packages\n",
        "import os\n",
        "os.environ[\"SM_FRAMEWORK\"] = \"tf.keras\"\n",
        "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\"\n",
        "\n",
        "# Import necessary libraries and mount Google Drive (if needed)\n",
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "import tensorflow.keras as keras\n",
        "print(\"tf.keras is available.\")\n",
        "\n",
        "import segmentation_models as sm\n",
        "import glob\n",
        "import cv2\n",
        "import nibabel as nib\n",
        "import kagglehub\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DJgvGe86E-O6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download Dataset From Kaggle"
      ],
      "metadata": {
        "id": "YA7hvlH7FiW0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the BraTS2020 dataset (training+validation) from Kaggle\n",
        "DATASET_NAME = \"awsaf49/brats20-dataset-training-validation\"\n",
        "dataset_path = kagglehub.dataset_download(DATASET_NAME)\n",
        "print(\"Dataset downloaded to:\", dataset_path)\n",
        "\n",
        "# Inspect the downloaded folder structure\n",
        "!ls -lh \"{dataset_path}\"\n",
        "\n",
        "# Copy the extracted TrainingData folder (which contains the patient subdirectories)\n",
        "!mkdir -p /content/brats_data\n",
        "!cp -r \"{dataset_path}/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\" /content/brats_data/\n",
        "\n",
        "# Set the training data directory to the copied folder\n",
        "BRATS_DATA_DIR = \"/content/brats_data/MICCAI_BraTS2020_TrainingData\"\n",
        "!ls -lh \"{BRATS_DATA_DIR}\""
      ],
      "metadata": {
        "id": "HUYP9WbrFLlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Functions"
      ],
      "metadata": {
        "id": "_aAWqNKpF9co"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_slices(nifti_path):\n",
        "    \"\"\"Load a 3D .nii volume and return a list of normalized 2D slices.\"\"\"\n",
        "    nii_img = nib.load(nifti_path)\n",
        "    data = nii_img.get_fdata()  # Shape: (H, W, Depth)\n",
        "    slices = []\n",
        "    for i in range(data.shape[2]):  # Iterate over axial slices\n",
        "        slice_data = data[:, :, i]\n",
        "        # Normalize to [0, 1]\n",
        "        slice_norm = (slice_data - np.min(slice_data)) / (np.max(slice_data) - np.min(slice_data) + 1e-8)\n",
        "        # Resize to 256x256\n",
        "        slice_resized = cv2.resize(slice_norm, (256, 256))\n",
        "        slices.append(slice_resized)\n",
        "    return slices\n",
        "\n",
        "def extract_mask_slices(nifti_path):\n",
        "    \"\"\"Load a 3D mask (.nii) and return 2D binary slices.\"\"\"\n",
        "    nii_mask = nib.load(nifti_path)\n",
        "    data = nii_mask.get_fdata()\n",
        "    slices = []\n",
        "    for i in range(data.shape[2]):\n",
        "        slice_data = data[:, :, i]\n",
        "        # Convert multi-class labels to binary: tumor vs. background\n",
        "        binary_slice = (slice_data > 0).astype(np.float32)\n",
        "        slice_resized = cv2.resize(binary_slice, (256, 256))\n",
        "        slices.append(slice_resized)\n",
        "    return slices\n",
        "\n",
        "def process_brats_data(brats_dir, save_dir=\"brats_slices\"):\n",
        "    \"\"\"\n",
        "    Processes BraTS data from a directory containing patient subdirectories.\n",
        "    Each patient directory should contain files like *_flair.nii and *_seg.nii.\n",
        "    save_dir: Folder where 2D slices will be stored (subfolders \"images\" and \"masks\" will be created).\n",
        "    \"\"\"\n",
        "    images_save_dir = os.path.join(save_dir, \"images\")\n",
        "    masks_save_dir  = os.path.join(save_dir, \"masks\")\n",
        "    os.makedirs(images_save_dir, exist_ok=True)\n",
        "    os.makedirs(masks_save_dir, exist_ok=True)\n",
        "\n",
        "    # Get all patient subdirectories in brats_dir (e.g., BraTS20_Training_314, etc.)\n",
        "    patient_dirs = glob.glob(os.path.join(brats_dir, \"BraTS20_Training_*\"))\n",
        "    slice_count = 0\n",
        "\n",
        "    for patient_dir in patient_dirs:\n",
        "        print(\"Processing patient:\", patient_dir)\n",
        "        # Look for flair and seg files within each patient directory\n",
        "        flair_files = glob.glob(os.path.join(patient_dir, \"*_flair.nii\"))\n",
        "        seg_files   = glob.glob(os.path.join(patient_dir, \"*_seg.nii\"))\n",
        "        if len(flair_files) == 0 or len(seg_files) == 0:\n",
        "            print(\"No flair or seg file found in\", patient_dir)\n",
        "            continue\n",
        "\n",
        "        flair_file = flair_files[0]\n",
        "        seg_file = seg_files[0]\n",
        "\n",
        "        flair_slices = extract_slices(flair_file)\n",
        "        seg_slices = extract_mask_slices(seg_file)\n",
        "\n",
        "        n_slices = min(len(flair_slices), len(seg_slices))\n",
        "        print(\"Found\", n_slices, \"slices in\", flair_file)\n",
        "\n",
        "        for i in range(n_slices):\n",
        "            # Convert flair slice to RGB by stacking the grayscale image into 3 channels\n",
        "            img_gray = (flair_slices[i] * 255).astype(np.uint8)\n",
        "            img_rgb = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2RGB)\n",
        "            msk = (seg_slices[i] * 255).astype(np.uint8)\n",
        "\n",
        "            base_name = os.path.basename(flair_file).replace(\"_flair.nii\", \"\")\n",
        "            img_filename = os.path.join(images_save_dir, f\"{base_name}_slice_{i}.png\")\n",
        "            msk_filename = os.path.join(masks_save_dir, f\"{base_name}_slice_{i}.png\")\n",
        "\n",
        "            cv2.imwrite(img_filename, img_rgb)\n",
        "            cv2.imwrite(msk_filename, msk)\n",
        "            slice_count += 1\n",
        "\n",
        "    print(f\"Total 2D slices saved: {slice_count}\")\n",
        "\n",
        "# Run the processing function\n",
        "process_brats_data(BRATS_DATA_DIR, save_dir=\"brats_slices\")\n",
        "\n",
        "# Verify that PNG files were created\n",
        "!ls -lh brats_slices/images\n",
        "!ls -lh brats_slices/masks"
      ],
      "metadata": {
        "id": "Al5TkxXLF8LX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting and Creating the Dataset"
      ],
      "metadata": {
        "id": "EWnTspl6GOf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set directories for images and masks\n",
        "IMAGE_DIR = \"brats_slices/images\"\n",
        "MASK_DIR = \"brats_slices/masks\"\n",
        "\n",
        "# Get sorted lists of image and mask file paths\n",
        "image_files = sorted(glob.glob(os.path.join(IMAGE_DIR, \"*.png\")))\n",
        "mask_files = sorted(glob.glob(os.path.join(MASK_DIR, \"*.png\")))\n",
        "\n",
        "print(\"Total images:\", len(image_files))\n",
        "print(\"Total masks:\", len(mask_files))\n",
        "\n",
        "# Split data into train, validation, and test sets\n",
        "train_img, temp_img, train_mask, temp_mask = train_test_split(\n",
        "    image_files, mask_files, test_size=0.2, random_state=42\n",
        ")\n",
        "val_img, test_img, val_mask, test_mask = train_test_split(\n",
        "    temp_img, temp_mask, test_size=0.5, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train slices:\", len(train_img))\n",
        "print(\"Val slices:\", len(val_img))\n",
        "print(\"Test slices:\", len(test_img))\n",
        "\n",
        "def load_image_mask(image_path, mask_path):\n",
        "    # Load image as RGB\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "    image = tf.image.resize(image, [256, 256])\n",
        "\n",
        "    # Load mask as grayscale\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.image.convert_image_dtype(mask, tf.float32)\n",
        "    mask = tf.image.resize(mask, [256, 256])\n",
        "    return image, mask\n",
        "\n",
        "def create_dataset(img_list, msk_list, batch_size=8):\n",
        "    ds = tf.data.Dataset.from_tensor_slices((img_list, msk_list))\n",
        "    ds = ds.map(load_image_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "train_dataset = create_dataset(train_img, train_mask, BATCH_SIZE)\n",
        "val_dataset = create_dataset(val_img, val_mask, BATCH_SIZE)\n",
        "test_dataset = create_dataset(test_img, test_mask, BATCH_SIZE)"
      ],
      "metadata": {
        "id": "M4Wb8niNGN6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Creation, Evaluation and Training"
      ],
      "metadata": {
        "id": "-T0bKQ4QHoim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "# Set up segmentation_models to use tf.keras\n",
        "sm.set_framework('tf.keras')\n",
        "sm.framework()\n",
        "\n",
        "# Define Dice coefficient metric for segmentation quality\n",
        "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "# Create the U-Net model with input shape for RGB images\n",
        "unet = sm.Unet(\n",
        "    backbone_name='resnet34',    # or choose another backbone if desired\n",
        "    encoder_weights='imagenet',\n",
        "    input_shape=(256, 256, 3),     # For RGB input\n",
        "    classes=1,                   # Binary segmentation: tumor vs. background\n",
        "    activation='sigmoid'\n",
        ")\n",
        "\n",
        "unet.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy', dice_coefficient]\n",
        ")\n",
        "\n",
        "unet.summary()\n",
        "\n",
        "# Train the model\n",
        "EPOCHS = 5\n",
        "history = unet.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS\n",
        ")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_acc, test_dice = unet.evaluate(test_dataset)\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Accuracy: {test_acc:.4f}\")\n",
        "print(f\"Test Dice: {test_dice:.4f}\")"
      ],
      "metadata": {
        "id": "F0_7yWfBHKBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification Report"
      ],
      "metadata": {
        "id": "W-4N5RdTIGVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Get one batch from the test dataset for demonstration:\n",
        "for images, masks in test_dataset.take(1):\n",
        "    preds = unet.predict(images)\n",
        "    # Threshold predictions at 0.5\n",
        "    preds_bin = (preds > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Flatten the ground truth and predicted masks (each pixel is a sample)\n",
        "    y_true = masks.numpy().flatten()\n",
        "    y_pred = preds_bin.flatten()\n",
        "\n",
        "    # Generate classification report\n",
        "    report = classification_report(y_true, y_pred, target_names=[\"Background\", \"Tumor\"])\n",
        "    print(report)"
      ],
      "metadata": {
        "id": "fG_NisDNIKxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Accuracy VS Validation Accuracy"
      ],
      "metadata": {
        "id": "NmOwpJ8dIhDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Plot accuracy\n",
        "axes[0].plot(history.history['accuracy'], label='Train Accuracy')\n",
        "axes[0].plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "axes[0].set_title('Train vs. Validation Accuracy')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Accuracy')\n",
        "axes[0].legend(loc='lower right')\n",
        "\n",
        "# Plot loss\n",
        "axes[1].plot(history.history['loss'], label='Train Loss')\n",
        "axes[1].plot(history.history['val_loss'], label='Validation Loss')\n",
        "axes[1].set_title('Train vs. Validation Loss')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Loss')\n",
        "axes[1].legend(loc='upper right')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a0ZYHpEvImue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Confusion Matrix"
      ],
      "metadata": {
        "id": "TTuI6ExaI-UW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assume we take one batch from test_dataset for demonstration\n",
        "for images, masks in test_dataset.take(1):\n",
        "    preds = unet.predict(images)\n",
        "    # Threshold predictions to obtain binary masks\n",
        "    preds_bin = (preds > 0.5).astype(np.uint8)\n",
        "\n",
        "    # Flatten the arrays (each pixel becomes a sample)\n",
        "    y_true = masks.numpy().flatten()\n",
        "    y_pred = preds_bin.flatten()\n",
        "\n",
        "    # Compute the confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "    # Plot the confusion matrix\n",
        "    plt.figure(figsize=(6,5))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=[\"Background\", \"Tumor\"],\n",
        "                yticklabels=[\"Background\", \"Tumor\"])\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "YePlqxqfJBWv"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1fVqyoQHbaPpjvI09Xrt43SbwgANTTeNc",
      "authorship_tag": "ABX9TyOh4B/lWGv/66dxwjlBHzFV",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}