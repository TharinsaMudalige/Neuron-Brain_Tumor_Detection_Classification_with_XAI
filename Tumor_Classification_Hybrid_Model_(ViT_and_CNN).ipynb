{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTNPClLD8bdMl1XxRDkkUK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classification-VIT/Tumor_Classification_Hybrid_Model_(ViT_and_CNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "gyuWwbFVltSa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA15Xi5mlcHM"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the preprocessed dataset"
      ],
      "metadata": {
        "id": "WHoHdmJ7lzB-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the dataset directory\n",
        "base_dir = \"/content/drive/MyDrive/Colab Notebooks/Preprocessed_Dataset_classification\""
      ],
      "metadata": {
        "id": "amsyJ1eVlyLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "2QSAmVpvnwMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exploratory Data Analysis (EDA)\n",
        "def perform_eda(images, labels, class_names):\n",
        "    \"\"\"Perform EDA on the dataset.\"\"\"\n",
        "    import pandas as pd\n",
        "\n",
        "    # 1. Dataset Overview\n",
        "    print(\"\\n--- Dataset Overview ---\")\n",
        "    print(f\"Total Images: {len(images)}\")\n",
        "    print(f\"Total Classes: {len(class_names)}\")\n",
        "    print(f\"Class Distribution: {np.bincount(labels)}\")\n",
        "    print(\"\\nClass Names with Distribution:\")\n",
        "    class_distribution = pd.DataFrame({\"Class\": class_names, \"Count\": np.bincount(labels)})\n",
        "    print(class_distribution)\n",
        "\n",
        "    # 2. Visualize Class Distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.barplot(x=class_distribution['Class'], y=class_distribution['Count'], palette=\"viridis\")\n",
        "    plt.title('Class Distribution')\n",
        "    plt.xlabel('Class')\n",
        "    plt.ylabel('Number of Samples')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "\n",
        "    # 3. Display Sample Images from Each Class\n",
        "    print(\"\\n--- Displaying Sample Images from Each Class ---\")\n",
        "    plt.figure(figsize=(24, 24))\n",
        "    for i, class_name in enumerate(class_names):\n",
        "        idx = labels.tolist().index(i)  # Get the first image index for this class\n",
        "        plt.subplot(1, len(class_names), i + 1)\n",
        "        plt.imshow(images[idx].squeeze(), cmap='gray')\n",
        "        plt.title(class_name)\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # 4. Image Shape and Value Distribution\n",
        "    print(\"\\n--- Image Shape and Value Distribution ---\")\n",
        "    print(f\"Image Shape: {images[0].shape}\")\n",
        "    print(f\"Pixel Intensity Range: Min = {np.min(images)}, Max = {np.max(images)}\")\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.hist(images.flatten(), bins=50, color='blue', alpha=0.7)\n",
        "    plt.title('Pixel Intensity Distribution')\n",
        "    plt.xlabel('Pixel Intensity')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.show()\n",
        "\n",
        "    # 5. Check for Class Imbalance\n",
        "    print(\"\\n--- Checking Class Imbalance ---\")\n",
        "    class_imbalance = np.bincount(labels)\n",
        "    max_samples = max(class_imbalance)\n",
        "    imbalance_ratio = max_samples / class_imbalance\n",
        "    print(f\"Imbalance Ratio: {imbalance_ratio}\")\n",
        "    if any(imbalance_ratio > 1.5):\n",
        "        print(\"Warning: Dataset has class imbalance.\")\n"
      ],
      "metadata": {
        "id": "J2cAMjRBoIEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to Load the dataset"
      ],
      "metadata": {
        "id": "mVRMtOD4oOl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(base_dir):\n",
        "    \"\"\"Load the dataset, preprocess images, convert grayscale to RGB, and return data and labels.\"\"\"\n",
        "    images, labels = [], []\n",
        "    class_names = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))])\n",
        "    print(f\"Class Names: {class_names}\")\n",
        "\n",
        "    for label, class_name in enumerate(class_names):\n",
        "        class_dir = os.path.join(base_dir, class_name)\n",
        "        for file in os.listdir(class_dir):\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                file_path = os.path.join(class_dir, file)\n",
        "                try:\n",
        "                    # Load the image in grayscale\n",
        "                    image = tf.io.read_file(file_path)\n",
        "                    image = tf.image.decode_image(image, channels=1)  # Load as grayscale\n",
        "                    image = tf.image.resize(image, [224, 224])  # Resize to 224x224\n",
        "                    image = tf.image.grayscale_to_rgb(image)  # Convert grayscale to RGB\n",
        "                    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "                    images.append(image.numpy())\n",
        "                    labels.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"[ERROR] Could not process {file_path}: {e}\")\n",
        "\n",
        "    images = np.array(images, dtype=np.float32)\n",
        "    labels = np.array(labels, dtype=np.int32)\n",
        "\n",
        "    # Display a sample image to confirm RGB conversion\n",
        "    if len(images) > 0:\n",
        "        plt.imshow(images[0])  # Matplotlib assumes (H, W, 3) as RGB\n",
        "        plt.title(f\"Sample Image (Class: {class_names[labels[0]]})\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    return images, labels, class_names\n"
      ],
      "metadata": {
        "id": "ho0HqcOooSTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset"
      ],
      "metadata": {
        "id": "XTyFVdXmoX6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and split the dataset\n",
        "images, labels, class_names = load_dataset(base_dir) # Assign class_names\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    images, labels, test_size=0.3, random_state=42, stratify=labels\n",
        ")"
      ],
      "metadata": {
        "id": "fK0z0wRWoXaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Further split training data into training (80%) and validation (20%)\n",
        "train_images, val_images, train_labels, val_labels = train_test_split(\n",
        "    train_images, train_labels, test_size=0.2, random_state=42, stratify=train_labels\n",
        ")"
      ],
      "metadata": {
        "id": "JR5V2f7mpPwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print dataset shapes\n",
        "print(f\"Training Images Shape: {train_images.shape}\")\n",
        "print(f\"Training Labels Shape: {train_labels.shape}\")\n",
        "print(f\"Validation Images Shape: {val_images.shape}\")\n",
        "print(f\"Validation Labels Shape: {val_labels.shape}\")\n",
        "print(f\"Test Images Shape: {test_images.shape}\")\n",
        "print(f\"Test Labels Shape: {test_labels.shape}\")"
      ],
      "metadata": {
        "id": "q2utDpoApSHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize EDA"
      ],
      "metadata": {
        "id": "xhGBoqZxpVX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform EDA on the dataset\n",
        "perform_eda(images, labels, class_names)"
      ],
      "metadata": {
        "id": "U1zOmM7wpUP9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create the Hybrid Model"
      ],
      "metadata": {
        "id": "yOx-e6tMpqEm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "def create_hybrid_vit_cnn_model(input_shape, num_classes, patch_size=32, embed_dim=64, num_heads=4, transformer_layers=4):\n",
        "    \"\"\"Build a Hybrid CNN-ViT Model.\"\"\"\n",
        "\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # CNN Feature Extractor\n",
        "    x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(inputs)\n",
        "    x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "    x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "    x = layers.Conv2D(128, (3,3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D(pool_size=(2,2))(x)\n",
        "\n",
        "    # Patch Embedding\n",
        "    x = layers.Conv2D(embed_dim, kernel_size=1, activation='relu')(x)  # Reduce depth\n",
        "    h, w = x.shape[1], x.shape[2]  # Get spatial dimensions\n",
        "    num_patches = (h * w)  # Compute correct number of patches\n",
        "    patches = layers.Reshape((num_patches, embed_dim))(x)  # Reshape CNN output\n",
        "\n",
        "    # Learnable Positional Embedding (Fix shape mismatch)\n",
        "    positional_embedding = tf.Variable(tf.random.normal([1, num_patches, embed_dim]), trainable=True)\n",
        "    x = patches + tf.broadcast_to(positional_embedding, tf.shape(patches))  # Ensure correct shape\n",
        "\n",
        "    # Transformer Encoder Layers\n",
        "    for _ in range(transformer_layers):\n",
        "        x_norm1 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim // num_heads)(x_norm1, x_norm1)\n",
        "        x = layers.Add()([x, attention_output])  # Residual connection\n",
        "\n",
        "        x_norm2 = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "        ff_output = layers.Dense(embed_dim * 2, activation='relu')(x_norm2)\n",
        "        ff_output = layers.Dense(embed_dim)(ff_output)\n",
        "        x = layers.Add()([x, ff_output])  # Residual connection\n",
        "\n",
        "    # Classification Head\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(x)\n",
        "    x = layers.GlobalAveragePooling1D()(x)  # Properly pool across patches\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Create Model\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "-1f-fT51psv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "input_shape = (224, 224, 3)  # Adjust according to dataset\n",
        "num_classes = 4  # Modify as needed\n",
        "\n",
        "hybrid_model = create_hybrid_vit_cnn_model(input_shape, num_classes)\n",
        "hybrid_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "hybrid_model.summary()"
      ],
      "metadata": {
        "id": "09mTm5cLt8bH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}