{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ZwQj-GOCFWYbwISojWo0cJOKKOkPinJT",
      "authorship_tag": "ABX9TyM07vgHFWERbiDCmtW+/cNJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classification-VIT/Tumor_Segmentation_using_U_NET_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Libraries"
      ],
      "metadata": {
        "id": "KiuZkR7a7nlr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-s4GUx4c5p15"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Datasets"
      ],
      "metadata": {
        "id": "_OHLRiYU8CiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to image and mask folders\n",
        "IMAGES_PATH = '/content/drive/MyDrive/DSGP_BrainTumorDetection/Segmentation Task/archive (3)/images'\n",
        "MASKS_PATH = '/content/drive/MyDrive/DSGP_BrainTumorDetection/Segmentation Task/archive (3)/masks'"
      ],
      "metadata": {
        "id": "iK9fL_3o8KML"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "SIZE = 128  # Reduced size to optimize memory usage\n",
        "CHANNEL = 1\n",
        "Num_Of_Classes = 1\n",
        "smooth = 1e-15"
      ],
      "metadata": {
        "id": "G2Zz8SxqKwR0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read Datasets"
      ],
      "metadata": {
        "id": "Bhxz_pk6K7j-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and sort image/mask files\n",
        "image_files = sorted(os.listdir(IMAGES_PATH))\n",
        "mask_files = sorted(os.listdir(MASKS_PATH))"
      ],
      "metadata": {
        "id": "pN0HyiIQwWSS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Debug: Ensure image and mask counts match\n",
        "assert len(image_files) == len(mask_files), \"Number of images and masks do not match!\""
      ],
      "metadata": {
        "id": "nBIjxwO1K7Ly"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display a few images and masks\n",
        "def display_images_masks(image_files, mask_files, imagepath, maskpath):\n",
        "    for count, (image_file, mask_file) in enumerate(zip(image_files, mask_files)):\n",
        "        if count >= 4:  # Display only 4 pairs\n",
        "            break\n",
        "        imagepath_full = os.path.join(imagepath, image_file)\n",
        "        maskpath_full = os.path.join(maskpath, mask_file)\n",
        "\n",
        "        image = cv2.imread(imagepath_full)\n",
        "        mask = cv2.imread(maskpath_full)\n",
        "\n",
        "        if image is None or mask is None:\n",
        "            raise ValueError(f\"Image or mask at path {imagepath_full} or {maskpath_full} could not be loaded\")\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "\n",
        "        # Display the image\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(image, cmap='gray')\n",
        "        plt.title('Image')\n",
        "\n",
        "        # Display the mask\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(mask, cmap='gray')\n",
        "        plt.title('Mask')\n",
        "\n",
        "        # Display contours\n",
        "        plt.subplot(1, 3, 3)\n",
        "        mask_gray = cv2.cvtColor(mask, cv2.COLOR_BGR2GRAY)\n",
        "        contours, _ = cv2.findContours(mask_gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "        overlay = cv2.drawContours(image.copy(), contours, -1, (0, 255, 0), thickness=2)\n",
        "        plt.imshow(overlay)\n",
        "        plt.title('Image with Contours')\n",
        "\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "63D9V6kMLZVw"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre Processing images and masks"
      ],
      "metadata": {
        "id": "R6Erb3Pzw-Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing images and masks\n",
        "def preprocessing_images_masks(image_files, mask_files, imagepath, maskpath):\n",
        "    images, masks = [], []\n",
        "    for image_file, mask_file in tqdm(zip(image_files, mask_files)):\n",
        "        imagepath_full = os.path.join(imagepath, image_file)\n",
        "        maskpath_full = os.path.join(maskpath, mask_file)\n",
        "\n",
        "        # Preprocess images\n",
        "        image = cv2.imread(imagepath_full, cv2.IMREAD_GRAYSCALE)\n",
        "        image = cv2.resize(image, (SIZE, SIZE))\n",
        "        image = image / 255.0\n",
        "        images.append(image)\n",
        "\n",
        "        # Preprocess masks\n",
        "        mask = cv2.imread(maskpath_full, cv2.IMREAD_GRAYSCALE)\n",
        "        mask = cv2.resize(mask, (SIZE, SIZE))\n",
        "        mask = mask / 255.0\n",
        "        masks.append(mask)\n",
        "\n",
        "    return np.expand_dims(np.array(images), axis=-1), np.expand_dims(np.array(masks), axis=-1)"
      ],
      "metadata": {
        "id": "oo7pR3i2LiKH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dice Coefficient and loss functions"
      ],
      "metadata": {
        "id": "vDBBeeP7LtK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dice coefficient and loss functions\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true_f = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred_f = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "fQ2o5lQcLvlj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "U-Net model"
      ],
      "metadata": {
        "id": "vauj1zpmxgc5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# U-Net model definition\n",
        "def unet_model(input_size=(SIZE, SIZE, CHANNEL), num_classes=Num_Of_Classes):\n",
        "    inputs = layers.Input(input_size)\n",
        "\n",
        "    # Encoding path\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(inputs)\n",
        "    c1 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)\n",
        "    p1 = layers.MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)\n",
        "    c2 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)\n",
        "    p2 = layers.MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)\n",
        "    c3 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)\n",
        "    p3 = layers.MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)\n",
        "    c4 = layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)\n",
        "    p4 = layers.MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    # Bottleneck\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)\n",
        "    c5 = layers.Conv2D(1024, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)\n",
        "\n",
        "    # Decoding path\n",
        "    u6 = layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(c5)\n",
        "    u6 = layers.concatenate([u6, c4])\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)\n",
        "    c6 = layers.Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)\n",
        "\n",
        "    u7 = layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(c6)\n",
        "    u7 = layers.concatenate([u7, c3])\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)\n",
        "    c7 = layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)\n",
        "\n",
        "    u8 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c7)\n",
        "    u8 = layers.concatenate([u8, c2])\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)\n",
        "    c8 = layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)\n",
        "\n",
        "    u9 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c8)\n",
        "    u9 = layers.concatenate([u9, c1])\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)\n",
        "    c9 = layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)\n",
        "\n",
        "    outputs = layers.Conv2D(num_classes, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    return models.Model(inputs=[inputs], outputs=[outputs])"
      ],
      "metadata": {
        "id": "fUcVJIp5x_yv"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}