{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classficiation-CNN/Generating_Annotations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Required Libraries"
      ],
      "metadata": {
        "id": "e8RAfeuzQfmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install tensorflow tensorflow-hub tensorflow-addons opencv-python\n",
        "\n",
        "# Import libraries\n",
        "import os\n",
        "import random\n",
        "import shutil\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom.minidom import parseString"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4j7zipaQhyp",
        "outputId": "0b4c5957-0e37-46e3-ed8a-04061a6f1a83"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.11/dist-packages (0.16.1)\n",
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.11/dist-packages (0.23.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow-hub) (2.18.0)\n",
            "Requirement already satisfied: typeguard<3.0.0,>=2.7 in /usr/local/lib/python3.11/dist-packages (from tensorflow-addons) (2.13.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive and Define paths"
      ],
      "metadata": {
        "id": "CJ49t6rEQjlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define paths\n",
        "RAW_DATASET_PATH = \"/content/drive/MyDrive/DSGP/DSGP_dataset\"\n",
        "OUTPUT_PATH = \"/content/drive/MyDrive/DSGP/CNN_Dataset\"\n",
        "\n",
        "# Detect tumor classes (from folders in dataset)\n",
        "tumor_classes = [folder for folder in os.listdir(RAW_DATASET_PATH) if os.path.isdir(os.path.join(RAW_DATASET_PATH, folder))]\n",
        "print(\"Detected tumor classes:\", tumor_classes)\n",
        "\n",
        "# Create folders for Train, Val, Test\n",
        "for split in [\"Train\", \"Val\", \"Test\"]:\n",
        "    for subdir in [\"Images\", \"Annotations\"]:\n",
        "        for tumor_class in tumor_classes:\n",
        "            os.makedirs(os.path.join(OUTPUT_PATH, split, subdir, tumor_class), exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRGnu6YXQnkE",
        "outputId": "5e1c9c13-dc39-45f7-aeaa-780ebe170fed"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Detected tumor classes: ['tuberculoma', 'granuloma', 'no_tumour', 'papiloma', 'schwannoma', 'meduloblastoma', 'pituitary', 'neurocitoma', 'oligodendroglioma', 'meningioma', 'germinoma', 'astrocitoma', 'glioblastoma', 'ependimoma', 'ganglioglioma', 'carcinoma']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load U-Net Model"
      ],
      "metadata": {
        "id": "CJYKo83KQq0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple U-Net model for segmentation\n",
        "def unet_model(input_size=(256, 256, 3)):\n",
        "    inputs = keras.Input(input_size)\n",
        "\n",
        "    # Encoder\n",
        "    conv1 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
        "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv3 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
        "\n",
        "    # Decoder\n",
        "    up4 = layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv3)\n",
        "    conv4 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(up4)\n",
        "\n",
        "    up5 = layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv4)\n",
        "    conv5 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(up5)\n",
        "\n",
        "    outputs = layers.Conv2D(1, (1, 1), activation='sigmoid')(conv5)\n",
        "\n",
        "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "# Compile U-Net model\n",
        "unet_model = unet_model()\n",
        "unet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(\"U-Net model built and compiled.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYAy8500Qtlg",
        "outputId": "add265d9-81a4-4404-cfa1-146decb9ece9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U-Net model built and compiled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resize and Preprocess Images"
      ],
      "metadata": {
        "id": "iHTaMQqaQwDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resize images to 256x256\n",
        "TARGET_SIZE = (256, 256)\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    \"\"\"Load, resize, and normalize MRI image.\"\"\"\n",
        "    image = load_img(image_path)\n",
        "    image = image.resize(TARGET_SIZE)\n",
        "    image = img_to_array(image) / 255.0\n",
        "    return image"
      ],
      "metadata": {
        "id": "uQnnGwk8Qyjn"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tumor Segmentation and Bounding Box Generation"
      ],
      "metadata": {
        "id": "aQTKc43tQ1gN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_segmentation_mask(image):\n",
        "    \"\"\"Generate tumor segmentation mask using U-Net.\"\"\"\n",
        "    img_resized = tf.image.resize(image, TARGET_SIZE)\n",
        "    img_resized = tf.expand_dims(img_resized, 0)\n",
        "    mask = unet_model(img_resized)\n",
        "    mask = tf.squeeze(mask, axis=0)\n",
        "    mask = np.array(mask > 0.5, dtype=np.uint8)\n",
        "    return mask\n",
        "\n",
        "def mask_to_bbox(mask, is_no_tumor=False):\n",
        "    \"\"\"Convert a binary mask to bounding box coordinates (xmin, ymin, xmax, ymax).\"\"\"\n",
        "    # If no tumor, assign full image as bounding box\n",
        "    if is_no_tumor:\n",
        "        return [0, 0, TARGET_SIZE[0], TARGET_SIZE[1]]\n",
        "\n",
        "    # Ensure mask is 2D (squeeze any extra dimensions)\n",
        "    if len(mask.shape) > 2:\n",
        "        mask = np.squeeze(mask)\n",
        "\n",
        "    # Identify tumor regions (non-zero areas)\n",
        "    y_indices, x_indices = np.where(mask > 0)\n",
        "\n",
        "    # Handle empty mask (no tumor detected)\n",
        "    if y_indices.size == 0 or x_indices.size == 0:\n",
        "        return [0, 0, TARGET_SIZE[0], TARGET_SIZE[1]]  # Assign full image for 'no_tumor'\n",
        "\n",
        "    # Calculate bounding box coordinates\n",
        "    xmin, xmax = np.min(x_indices), np.max(x_indices)\n",
        "    ymin, ymax = np.min(y_indices), np.max(y_indices)\n",
        "\n",
        "    return [int(xmin), int(ymin), int(xmax), int(ymax)]"
      ],
      "metadata": {
        "id": "PKUBVEsAQ4EW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation for Class Imbalance"
      ],
      "metadata": {
        "id": "stmtqMiFQ68c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define data augmentation strategies\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "def augment_image(image, count):\n",
        "    \"\"\"Generate augmented images.\"\"\"\n",
        "    augmented_images = []\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    for _ in range(count):\n",
        "        aug_img = next(augmentor.flow(image, batch_size=1))[0]\n",
        "        augmented_images.append(aug_img)\n",
        "    return augmented_images"
      ],
      "metadata": {
        "id": "0TukaSttQ9sp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Splitting and Balancing"
      ],
      "metadata": {
        "id": "V8kSEXpbm5Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_balance_dataset(images, max_count):\n",
        "    \"\"\"Split and balance the dataset.\"\"\"\n",
        "    train, temp = train_test_split(images, test_size=0.3, random_state=42)\n",
        "    val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "    train = balance_class(train, max_count)\n",
        "    return train, val, test\n",
        "\n",
        "def balance_class(images, max_count):\n",
        "    \"\"\"Balance classes using augmentation.\"\"\"\n",
        "    current_count = len(images)\n",
        "    augmented_images = []\n",
        "    if current_count < max_count:\n",
        "        extra_images = max_count - current_count\n",
        "        for image_path in random.choices(images, k=extra_images):\n",
        "            img = preprocess_image(image_path)\n",
        "            aug_imgs = augment_image(img, 1)\n",
        "            augmented_images.append((aug_imgs[0], image_path))\n",
        "    return images + [img_path for _, img_path in augmented_images]"
      ],
      "metadata": {
        "id": "rtF5Tljem8K1"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating Annotations"
      ],
      "metadata": {
        "id": "XGyOOPyqm_N9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_pascal_voc_xml(image_path, bbox, label, save_dir):\n",
        "    \"\"\"Generate PASCAL VOC annotations.\"\"\"\n",
        "    image_name = os.path.basename(image_path)\n",
        "    xml_filename = os.path.splitext(image_name)[0] + \".xml\"\n",
        "\n",
        "    root = ET.Element(\"annotation\")\n",
        "    ET.SubElement(root, \"filename\").text = image_name\n",
        "    ET.SubElement(root, \"path\").text = image_path\n",
        "\n",
        "    size = ET.SubElement(root, \"size\")\n",
        "    ET.SubElement(size, \"width\").text = str(TARGET_SIZE[0])\n",
        "    ET.SubElement(size, \"height\").text = str(TARGET_SIZE[1])\n",
        "\n",
        "    obj = ET.SubElement(root, \"object\")\n",
        "    ET.SubElement(obj, \"name\").text = label\n",
        "    bbox_elem = ET.SubElement(obj, \"bndbox\")\n",
        "    ET.SubElement(bbox_elem, \"xmin\").text = str(bbox[0])\n",
        "    ET.SubElement(bbox_elem, \"ymin\").text = str(bbox[1])\n",
        "    ET.SubElement(bbox_elem, \"xmax\").text = str(bbox[2])\n",
        "    ET.SubElement(bbox_elem, \"ymax\").text = str(bbox[3])\n",
        "\n",
        "    with open(os.path.join(save_dir, xml_filename), \"w\") as xml_file:\n",
        "        xml_file.write(parseString(ET.tostring(root)).toprettyxml())"
      ],
      "metadata": {
        "id": "d9KUYL-SnBeR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Folder Structure"
      ],
      "metadata": {
        "id": "M0MeUDbDT9pP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_folder_structure(base_path):\n",
        "    \"\"\"Print the folder structure after preprocessing.\"\"\"\n",
        "    for root, dirs, files in os.walk(base_path):\n",
        "        level = root.replace(base_path, \"\").count(os.sep)\n",
        "        indent = \" \" * 2 * level\n",
        "        print(f\"{indent}{os.path.basename(root)}/\")\n",
        "        sub_indent = \" \" * 2 * (level + 1)\n",
        "        for file in files:\n",
        "            print(f\"{sub_indent}{file}\")"
      ],
      "metadata": {
        "id": "hHILBQwrUAMA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocess the Dataset"
      ],
      "metadata": {
        "id": "kJ8EbXp0Tihr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset():\n",
        "    \"\"\"Preprocess images, generate masks, and save with bounding boxes.\"\"\"\n",
        "    for tumor_class in tumor_classes:\n",
        "        class_path = os.path.join(RAW_DATASET_PATH, tumor_class)\n",
        "        images = [os.path.join(class_path, img) for img in os.listdir(class_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "        # Get max count for class balancing\n",
        "        max_count = max(len(os.listdir(os.path.join(RAW_DATASET_PATH, cls))) for cls in tumor_classes)\n",
        "\n",
        "        # Split into Train, Val, Test sets\n",
        "        train, temp = train_test_split(images, test_size=0.3, random_state=42)\n",
        "        val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
        "\n",
        "        # Balance training data\n",
        "        train = balance_class(train, max_count)\n",
        "\n",
        "        # Process each split\n",
        "        for split, split_data in zip([\"Train\", \"Val\", \"Test\"], [train, val, test]):\n",
        "            for image_path in split_data:\n",
        "                # Preprocess image and generate mask\n",
        "                image = preprocess_image(image_path)\n",
        "                mask = get_segmentation_mask(image)\n",
        "                bbox = mask_to_bbox(mask)\n",
        "\n",
        "                # Define save directories\n",
        "                img_dest = os.path.join(OUTPUT_PATH, split, \"Images\", tumor_class)\n",
        "                ann_dest = os.path.join(OUTPUT_PATH, split, \"Annotations\", tumor_class)\n",
        "\n",
        "                # Save processed image and annotation\n",
        "                shutil.copy(image_path, img_dest)\n",
        "                create_pascal_voc_xml(image_path, bbox, tumor_class, ann_dest)\n",
        "\n",
        "                print(f\"{split}: {os.path.basename(image_path)} -> {tumor_class}\")\n",
        "\n",
        "    print(\"Dataset processing completed successfully.\")"
      ],
      "metadata": {
        "id": "j1vUDe99Tkvy"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Preprocessing Function"
      ],
      "metadata": {
        "id": "QkGP2jbhuY4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Main function to run full preprocessing pipeline\n",
        "def main():\n",
        "    print(\"Starting dataset preprocessing...\")\n",
        "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(RAW_DATASET_PATH):\n",
        "        print(f\"Error: RAW_DATASET_PATH does not exist: {RAW_DATASET_PATH}\")\n",
        "        return\n",
        "\n",
        "    process_dataset()\n",
        "\n",
        "    # Count and plot class distributions\n",
        "    before_balancing_counts = count_images_per_class(RAW_DATASET_PATH)\n",
        "    after_balancing_counts = count_images_per_class(os.path.join(OUTPUT_PATH, \"Train/Images\"))\n",
        "    plot_class_distributions(before_balancing_counts, after_balancing_counts)\n",
        "\n",
        "    print(\"\\n Preprocessing complete! Final folder structure:\")\n",
        "    check_folder_structure(OUTPUT_PATH)\n",
        "\n",
        "# Execute main function\n",
        "main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "6oP9jTm7ubnC",
        "outputId": "efaab65e-8a2e-4059-e96e-a49a357dc0b7"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting dataset preprocessing...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/DSGP/CNN_Dataset/Train/Images/tuberculoma'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-919db8b15579>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Execute main function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-40-919db8b15579>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Count and plot class distributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-6ad73bee47ee>\u001b[0m in \u001b[0;36mprocess_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;31m# Save processed image and annotation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                 \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_dest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m                 \u001b[0mcreate_pascal_voc_xml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtumor_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mann_dest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m         \u001b[0mdst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m     \u001b[0mcopymode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_symlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdst\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/shutil.py\u001b[0m in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfsrc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m                     \u001b[0;31m# macOS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0m_HAS_FCOPYFILE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/DSGP/CNN_Dataset/Train/Images/tuberculoma'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize Class Imbalance handling"
      ],
      "metadata": {
        "id": "sSZ53wEDTMlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Count images per class before and after balancing\n",
        "def count_images_per_class(base_path):\n",
        "    \"\"\"Count the number of images in each class directory.\"\"\"\n",
        "    class_counts = {}\n",
        "    for tumor_class in tumor_classes:\n",
        "        class_path = os.path.join(base_path, tumor_class)\n",
        "        num_images = len([img for img in os.listdir(class_path) if img.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "        class_counts[tumor_class] = num_images\n",
        "    return class_counts\n",
        "\n",
        "# Count images before and after balancing\n",
        "before_balancing_counts = count_images_per_class(RAW_DATASET_PATH)\n",
        "after_balancing_counts = count_images_per_class(os.path.join(OUTPUT_PATH, \"Train/Images\"))\n",
        "\n",
        "print(\"Class counts before balancing:\", before_balancing_counts)\n",
        "print(\"Class counts after balancing:\", after_balancing_counts)"
      ],
      "metadata": {
        "id": "FaBj1AurTQyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_class_distributions(before_counts, after_counts):\n",
        "    \"\"\"Plot side-by-side comparison of class distributions.\"\"\"\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "    # Before balancing\n",
        "    axes[0].bar(before_counts.keys(), before_counts.values(), color='skyblue')\n",
        "    axes[0].set_title(\"Class Distribution Before Balancing\")\n",
        "    axes[0].set_xlabel(\"Tumor Classes\")\n",
        "    axes[0].set_ylabel(\"Number of Images\")\n",
        "    axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # After balancing\n",
        "    axes[1].bar(after_counts.keys(), after_counts.values(), color='salmon')\n",
        "    axes[1].set_title(\"Class Distribution After Balancing\")\n",
        "    axes[1].set_xlabel(\"Tumor Classes\")\n",
        "    axes[1].set_ylabel(\"Number of Images\")\n",
        "    axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot class distributions\n",
        "plot_class_distributions(before_balancing_counts, after_balancing_counts)"
      ],
      "metadata": {
        "id": "6dmlxQacTQ-i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}