{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classficiation-CNN/Faster_R_CNN_for_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSq2BZ4QGdxG"
      },
      "source": [
        "Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "NSw-lQTgGf1P"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import cv2\n",
        "import xml.etree.ElementTree as ET\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from torchvision.models.detection import FasterRCNN\n",
        "from torchvision.models.detection.rpn import AnchorGenerator\n",
        "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\n",
        "\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dyoe-AgeGj2t"
      },
      "source": [
        "Define File paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FlaktKDXGmQk",
        "outputId": "0c17d3e7-1396-4105-ac2a-6ca10f54aadb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define dataset paths\n",
        "DATASET_PATH = \"/content/drive/MyDrive/DSGP/Preprocessed_Dataset\"\n",
        "TRAIN_PATH = os.path.join(DATASET_PATH, \"Train\")\n",
        "TEST_PATH = os.path.join(DATASET_PATH, \"Test\")\n",
        "VAL_PATH = os.path.join(DATASET_PATH, \"Val\")\n",
        "\n",
        "# Check dataset structure\n",
        "if not os.path.exists(TRAIN_PATH):\n",
        "    raise FileNotFoundError(f\"Train folder not found: {TRAIN_PATH}\")\n",
        "if not os.path.exists(TEST_PATH):\n",
        "    raise FileNotFoundError(f\"Test folder not found: {TEST_PATH}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Di4Evbsx6S1p"
      },
      "source": [
        "Define Custom Faster R-CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "JI5rlnhZKAvg"
      },
      "outputs": [],
      "source": [
        "class CustomFasterRCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(CustomFasterRCNN, self).__init__()\n",
        "\n",
        "        # Use a ResNet50 backbone without pretrained weights\n",
        "        backbone = resnet_fpn_backbone('resnet50', pretrained=False)\n",
        "\n",
        "        # Adjusted anchor generator\n",
        "        rpn_anchor_generator = AnchorGenerator(\n",
        "            sizes=([32], [64], [128], [256], [512]),\n",
        "            aspect_ratios=([0.5, 1.0, 2.0],) * 5\n",
        "        )\n",
        "\n",
        "        # Define the Faster R-CNN model\n",
        "        self.model = FasterRCNN(\n",
        "            backbone,\n",
        "            num_classes=num_classes,\n",
        "            rpn_anchor_generator=rpn_anchor_generator\n",
        "        )\n",
        "\n",
        "    def forward(self, images, targets=None):\n",
        "        return self.model(images, targets)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uJqggka06aKI"
      },
      "source": [
        "Define Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "ZZsp80naKOO8"
      },
      "outputs": [],
      "source": [
        "# Custom Dataset Class\n",
        "class TumorDataset(Dataset):\n",
        "    def __init__(self, root_dir, transforms=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transforms = transforms\n",
        "        self.image_files = []\n",
        "        self.annotation_files = []\n",
        "        self.labels_set = set()\n",
        "\n",
        "        images_path = os.path.join(root_dir, \"Images\")\n",
        "        annotations_path = os.path.join(root_dir, \"Annotations\")\n",
        "\n",
        "        # Ensure folders exist\n",
        "        if not os.path.exists(images_path):\n",
        "            raise FileNotFoundError(f\"Missing 'Images' directory in {root_dir}\")\n",
        "        if not os.path.exists(annotations_path):\n",
        "            raise FileNotFoundError(f\"Missing 'Annotations' directory in {root_dir}\")\n",
        "\n",
        "        for tumor_type in sorted(os.listdir(images_path)):\n",
        "            tumor_images_dir = os.path.join(images_path, tumor_type)\n",
        "            tumor_annotations_dir = os.path.join(annotations_path, tumor_type)\n",
        "\n",
        "            if not os.path.isdir(tumor_images_dir) or not os.path.isdir(tumor_annotations_dir):\n",
        "                continue\n",
        "\n",
        "            # Sort files to maintain order\n",
        "            tumor_images = sorted(os.listdir(tumor_images_dir))\n",
        "            tumor_annotations = sorted(os.listdir(tumor_annotations_dir))\n",
        "\n",
        "            for image in tumor_images:\n",
        "                image_path = os.path.join(tumor_images_dir, image)\n",
        "                annotation_path = os.path.join(tumor_annotations_dir, os.path.splitext(image)[0] + \".xml\")\n",
        "\n",
        "                if os.path.exists(annotation_path):\n",
        "                    self.image_files.append(image_path)\n",
        "                    self.annotation_files.append(annotation_path)\n",
        "\n",
        "                    # Extract labels from annotation\n",
        "                    _, labels = self.parse_annotation(annotation_path)\n",
        "                    self.labels_set.update(labels)\n",
        "\n",
        "        # Create a fixed label mapping\n",
        "        self.label_dict = {name: idx + 1 for idx, name in enumerate(sorted(self.labels_set))}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def parse_annotation(self, annotation_path):\n",
        "        tree = ET.parse(annotation_path)\n",
        "        root = tree.getroot()\n",
        "\n",
        "        boxes = []\n",
        "        labels = []\n",
        "\n",
        "        for obj in root.findall(\"object\"):\n",
        "            name = obj.find(\"name\").text\n",
        "            labels.append(name)  # Tumor class name\n",
        "\n",
        "            bbox = obj.find(\"bndbox\")\n",
        "            xmin = int(bbox.find(\"xmin\").text)\n",
        "            ymin = int(bbox.find(\"ymin\").text)\n",
        "            xmax = int(bbox.find(\"xmax\").text)\n",
        "            ymax = int(bbox.find(\"ymax\").text)\n",
        "\n",
        "            boxes.append([xmin, ymin, xmax, ymax])\n",
        "\n",
        "        return np.array(boxes, dtype=np.float32), labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_files[idx]\n",
        "        annotation_path = self.annotation_files[idx]\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "        boxes, labels = self.parse_annotation(annotation_path)\n",
        "\n",
        "        labels = [self.label_dict[label] for label in labels]\n",
        "\n",
        "\n",
        "        target = {\n",
        "            \"boxes\": torch.tensor(boxes, dtype=torch.float32),\n",
        "            \"labels\": labels\n",
        "        }\n",
        "\n",
        "        if self.transforms:\n",
        "            label_strings = [str(label) for label in labels]\n",
        "            sample = self.transforms(image=image, bboxes=boxes, class_labels=labels)\n",
        "            image = sample[\"image\"]\n",
        "            target[\"boxes\"] = torch.tensor(sample[\"bboxes\"], dtype=torch.float32)\n",
        "\n",
        "        return image, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAfjzpff6fx1"
      },
      "source": [
        "Define Data Transformations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "gUsvCadHKUPa"
      },
      "outputs": [],
      "source": [
        "transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "    A.pytorch.transforms.ToTensorV2()\n",
        "], bbox_params=A.BboxParams(format='pascal_voc', label_fields=['class_labels']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FEFCC6-6mN8"
      },
      "source": [
        "Load dataset and DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WYtpgp3FKbhc"
      },
      "outputs": [],
      "source": [
        "train_dataset = TumorDataset(TRAIN_PATH, transforms=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=lambda x: tuple(zip(*x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k3e19lU6tus"
      },
      "source": [
        "Initialize Model and Training Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "__PBNfa2KhkC"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Get number of tumor classes\n",
        "unique_classes = set()\n",
        "for annotation in train_dataset.annotation_files:\n",
        "    tree = ET.parse(annotation)\n",
        "    root = tree.getroot()\n",
        "    for obj in root.findall(\"object\"):\n",
        "        unique_classes.add(obj.find(\"name\").text)\n",
        "\n",
        "num_classes = len(unique_classes) + 1  # Tumor classes + background\n",
        "\n",
        "# Initialize custom Faster R-CNN model\n",
        "model = CustomFasterRCNN(num_classes=num_classes)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXMbUxA16zav"
      },
      "source": [
        "Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMORaqHRKnbX"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1\n",
        "losses = []\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, targets in train_loader:\n",
        "        images = list(image.to(device) for image in images)\n",
        "        targets = [{k: torch.tensor(v).to(device) if isinstance(v, list) else v.to(device) for k, v in t.items()} for t in targets]\n",
        "\n",
        "        loss_dict = model(images, targets)\n",
        "        loss = sum(loss for loss in loss_dict.values())\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    losses.append(total_loss)\n",
        "    print(f\"Epoch {epoch+1}, Loss: {total_loss}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHpF3VPR64G6"
      },
      "source": [
        "Plot Training Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZYYNviYKzYT"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, num_epochs + 1), losses, marker='o', linestyle='-', color='b')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Training Loss\")\n",
        "plt.title(\"Training Loss Over Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7Ilfk9I68U0"
      },
      "source": [
        "Save the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEjmBZRj6-hK"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/DSGP/faster_rcnn_tumor_classification.pth\")\n",
        "print(\"Model saved!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RkCEwd2N7BOW"
      },
      "source": [
        "Evaluate the Model on Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeAkQOlK7Eb1"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "image_path = \"/content/drive/MyDrive/DSGP/CNN_dataset/Test/Images/astrocitoma/sample.jpg\"\n",
        "\n",
        "image = cv2.imread(image_path)\n",
        "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "image_transformed = transform(image=image)[\"image\"].unsqueeze(0).to(device)\n",
        "output = model(image_transformed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4mma8LB7HAI"
      },
      "source": [
        "Compute the IoU Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IB0gK3xR7JI0"
      },
      "outputs": [],
      "source": [
        "# Function to Calculate IoU\n",
        "def calculate_iou(boxA, boxB):\n",
        "    \"\"\"Calculate Intersection over Union (IoU).\"\"\"\n",
        "    xA = max(boxA[0], boxB[0])\n",
        "    yA = max(boxA[1], boxB[1])\n",
        "    xB = min(boxA[2], boxB[2])\n",
        "    yB = min(boxA[3], boxB[3])\n",
        "\n",
        "    intersection = max(0, xB - xA) * max(0, yB - yA)\n",
        "    boxA_area = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
        "    boxB_area = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
        "    union = boxA_area + boxB_area - intersection\n",
        "\n",
        "    return intersection / union if union > 0 else 0\n",
        "\n",
        "# Compute IoU\n",
        "ious = []\n",
        "for i, target in enumerate(output[0]['boxes']):\n",
        "    iou = calculate_iou(target.cpu().numpy(), train_dataset.parse_annotation(image_path)[0])\n",
        "    ious.append(iou)\n",
        "\n",
        "# Plot IoU Scores\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.hist(ious, bins=20, color='g', alpha=0.7)\n",
        "plt.xlabel(\"IoU Score\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(\"IoU Score Distribution\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyObeqdLmjsd11RGD3U1s7AO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}