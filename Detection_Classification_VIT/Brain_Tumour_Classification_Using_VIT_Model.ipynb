{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JDwjivSDXlkZe13NnnRVW0WdyjY29GA9",
      "authorship_tag": "ABX9TyPKMlL+4bLvghhwaN6cchgI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classification-VIT/Brain_Tumour_Classification_Using_VIT_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TDRADPlHGRPF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset directory\n",
        "base_dir = \"/content/drive/MyDrive/DSGP_BrainTumorDetection/Preprocessed_Dataset_classes_morepreprocess_techniques\"\n"
      ],
      "metadata": {
        "id": "GdQ2CQGr0n4u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(base_dir):\n",
        "    \"\"\"Load images and labels from the dataset.\"\"\"\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    # Ignore hidden folders\n",
        "    class_names = sorted([d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d)) and not d.startswith('.')])\n",
        "\n",
        "    print(f\"Class Names: {class_names}\")\n",
        "\n",
        "    for label, class_name in enumerate(class_names):\n",
        "        class_dir = os.path.join(base_dir, class_name)\n",
        "        print(f\"Processing class: {class_name}, Label: {label}\")\n",
        "\n",
        "        for file in os.listdir(class_dir):\n",
        "            if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
        "                file_path = os.path.join(class_dir, file)\n",
        "                try:\n",
        "                    image = tf.keras.preprocessing.image.load_img(\n",
        "                        file_path, color_mode='grayscale', target_size=(224, 224)\n",
        "                    )\n",
        "                    image = tf.keras.preprocessing.image.img_to_array(image) / 255.0\n",
        "                    images.append(image)\n",
        "                    labels.append(label)\n",
        "                except Exception as e:\n",
        "                    print(f\"[ERROR] Failed to process {file_path}: {e}\")\n",
        "\n",
        "    print(f\"Loaded {len(images)} images.\")\n",
        "\n",
        "    images_np = np.array(images, dtype=np.float32)\n",
        "    labels_np = np.array(labels, dtype=np.int32)\n",
        "\n",
        "    return images_np, labels_np, class_names\n"
      ],
      "metadata": {
        "id": "yIuRoZhBfTAQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "images, labels, class_names = load_dataset(base_dir)\n",
        "print(f\"Dataset loaded: {images.shape}, {labels.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JedXGsQN1WAu",
        "outputId": "ce95b832-4abe-4ae2-950e-ffe3cb695672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Names: ['Astrocitoma', 'Carcinoma', 'Ependimoma', 'Ganglioglioma', 'Germinoma', 'Glioblastoma', 'Granuloma', 'Meduloblastoma', 'Neurocitoma', 'Oligodendroglioma', 'Papiloma', 'Schwannoma', 'Tuberculoma', 'meningioma', 'no_tumour', 'pituitary']\n",
            "Processing class: Astrocitoma, Label: 0\n",
            "Processing class: Carcinoma, Label: 1\n",
            "Processing class: Ependimoma, Label: 2\n",
            "Processing class: Ganglioglioma, Label: 3\n",
            "Processing class: Germinoma, Label: 4\n",
            "Processing class: Glioblastoma, Label: 5\n",
            "Processing class: Granuloma, Label: 6\n",
            "Processing class: Meduloblastoma, Label: 7\n",
            "Processing class: Neurocitoma, Label: 8\n",
            "Processing class: Oligodendroglioma, Label: 9\n",
            "Processing class: Papiloma, Label: 10\n",
            "Processing class: Schwannoma, Label: 11\n",
            "Processing class: Tuberculoma, Label: 12\n",
            "Processing class: meningioma, Label: 13\n",
            "Processing class: no_tumour, Label: 14\n",
            "Processing class: pituitary, Label: 15\n",
            "Loaded 32000 images.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset equally for each class\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(\n",
        "    images, labels, test_size=0.3, random_state=42, stratify=labels\n",
        ")\n",
        "\n",
        "for label in range(len(class_names)):  # Iterate over each class label\n",
        "    class_indices = np.where(labels == label)[0]  # Get indices of all images belonging to the current class\n",
        "    class_images = images[class_indices]  # Extract images for the current class\n",
        "    class_labels = labels[class_indices]  # Extract labels for the current class\n",
        "    # Split the class data into training and testing sets (80% train, 20% test)\n",
        "    train_x, test_x, train_y, test_y = train_test_split(class_images, class_labels, test_size=0.3, random_state=42)\n",
        "    train_images.extend(train_x)  # Add training images to the train list\n",
        "    test_images.extend(test_x)  # Add testing images to the test list\n",
        "    train_labels.extend(train_y)  # Add training labels to the train list\n",
        "    test_labels.extend(test_y)  # Add testing labels to the test list\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "train_images = np.array(train_images)\n",
        "test_images = np.array(test_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "fpA1IGEo1uEB",
        "outputId": "e7a46b90-6618-4a84-f87f-6908d65bd312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'class_names' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5a668ff6709a>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Initialize empty lists for train/test splits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Iterate over each class label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mclass_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Get indices of all images belonging to the current class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mclass_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_indices\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Extract images for the current class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vit_model(input_shape, num_classes):\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Patch embedding\n",
        "    patch_size = 16\n",
        "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)\n",
        "    patches = layers.Conv2D(64, patch_size, patch_size)(inputs)\n",
        "    patches = layers.Reshape((num_patches, -1))(patches)\n",
        "\n",
        "    # Positional embedding\n",
        "    positional_embedding = layers.Embedding(input_dim=num_patches, output_dim=64)(tf.range(num_patches))\n",
        "    x = patches + positional_embedding\n",
        "\n",
        "    # Transformer blocks\n",
        "    for _ in range(4):\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)\n",
        "        x = layers.Add()([x, attention_output])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "        ff_output = layers.Dense(128, activation='relu')(x)\n",
        "        ff_output = layers.Dense(64)(ff_output)\n",
        "        x = layers.Add()([x, ff_output])\n",
        "        x = layers.LayerNormalization()(x)\n",
        "\n",
        "    # Classification head\n",
        "    x = layers.GlobalAveragePooling1D()(x)\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    return models.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "sPmnh9ms5qF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ViT model\n",
        "input_shape = (224, 224, 1)  # Input shape for grayscale images\n",
        "num_classes = len(class_names)  # Number of classes (tumor types + no tumor)\n",
        "model = create_vit_model(input_shape, num_classes)  # Build the model\n"
      ],
      "metadata": {
        "id": "yZNnLJUZ50In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile with Adam optimizer\n",
        "\n",
        "# Step 3: Train the model\n",
        "history = model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=20, batch_size=32)  # Train the model\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "predictions = model.predict(test_images)  # Predict on the test set\n",
        "predicted_labels = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n"
      ],
      "metadata": {
        "id": "LBe-Mo_vBG3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels, predicted_labels, target_names=class_names))  # Print detailed metrics\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(test_labels, predicted_labels)  # Compute confusion matrix\n",
        "plt.figure(figsize=(12, 10))  # Set figure size\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)  # Plot heatmap\n",
        "plt.xlabel('Predicted Labels')  # Label for x-axis\n",
        "plt.ylabel('True Labels')  # Label for y-axis\n",
        "plt.title('Confusion Matrix')  # Title of the plot\n",
        "plt.show()  # Display the plot\n",
        "\n"
      ],
      "metadata": {
        "id": "76JbPnX7_dHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Plot training and validation metrics\n",
        "def plot_metrics(history):\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Accuracy\n",
        "    if 'accuracy' in history.history and 'val_accuracy' in history.history:\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "        plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "        plt.title('Accuracy Over Epochs')\n",
        "        plt.xlabel('Epochs')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Loss Over Epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "qzefzsCVRwVq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
