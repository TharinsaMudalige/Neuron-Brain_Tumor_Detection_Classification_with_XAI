{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JDwjivSDXlkZe13NnnRVW0WdyjY29GA9",
      "authorship_tag": "ABX9TyMg5EvMZPMXPwLySFcUGJdr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classification-VIT/Brain_Tumour_Classification_Using_VIT_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "TDRADPlHGRPF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load and preprocess the dataset\n",
        "def load_dataset(base_dir):\n",
        "    \"\"\"Load images and labels from the dataset.\"\"\"\n",
        "    images = []  # List to store image data\n",
        "    labels = []  # List to store corresponding labels\n",
        "    class_names = sorted(os.listdir(base_dir))  # Get class names from folder names\n",
        "\n",
        "    for label, class_name in enumerate(class_names):  # Iterate over each class\n",
        "        class_dir = os.path.join(base_dir, class_name)  # Path to the class folder\n",
        "        for file in os.listdir(class_dir):  # Iterate over each image file in the folder\n",
        "            file_path = os.path.join(class_dir, file)  # Full path to the image file\n",
        "            # Load image as grayscale and resize to 224x224\n",
        "            image = tf.keras.preprocessing.image.load_img(file_path, color_mode='grayscale', target_size=(224, 224))\n",
        "            # Convert the image to a numpy array and normalize pixel values to [0, 1]\n",
        "            image = tf.keras.preprocessing.image.img_to_array(image) / 255.0\n",
        "            images.append(image)  # Add the image to the list\n",
        "            labels.append(label)  # Add the label to the list\n",
        "\n",
        "    return np.array(images), np.array(labels), class_names  # Return the images, labels, and class names\n"
      ],
      "metadata": {
        "id": "mvNPN8630iFG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define dataset directory\n",
        "base_dir = \"/content/drive/MyDrive/DSGP_BrainTumorDetection/Preprocessed_Dataset_classes_morepreprocess_techniques\"  # Path to the dataset folder\n"
      ],
      "metadata": {
        "id": "GdQ2CQGr0n4u"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "images, labels, class_names = load_dataset(base_dir)  # Load images, labels, and class names\n"
      ],
      "metadata": {
        "id": "JedXGsQN1WAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset equally for each class\n",
        "train_images, test_images, train_labels, test_labels = [], [], [], []  # Initialize empty lists for train/test splits\n",
        "for label in range(len(class_names)):  # Iterate over each class label\n",
        "    class_indices = np.where(labels == label)[0]  # Get indices of all images belonging to the current class\n",
        "    class_images = images[class_indices]  # Extract images for the current class\n",
        "    class_labels = labels[class_indices]  # Extract labels for the current class\n",
        "    # Split the class data into training and testing sets (80% train, 20% test)\n",
        "    train_x, test_x, train_y, test_y = train_test_split(class_images, class_labels, test_size=0.2, random_state=42)\n",
        "    train_images.extend(train_x)  # Add training images to the train list\n",
        "    test_images.extend(test_x)  # Add testing images to the test list\n",
        "    train_labels.extend(train_y)  # Add training labels to the train list\n",
        "    test_labels.extend(test_y)  # Add testing labels to the test list\n"
      ],
      "metadata": {
        "id": "fpA1IGEo1uEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert lists to numpy arrays\n",
        "train_images = np.array(train_images)\n",
        "test_images = np.array(test_images)\n",
        "train_labels = np.array(train_labels)\n",
        "test_labels = np.array(test_labels)\n"
      ],
      "metadata": {
        "id": "u_f8VxOd5hkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Create the Vision Transformer (ViT) model\n",
        "def create_vit_model(input_shape, num_classes):\n",
        "    \"\"\"Create a Vision Transformer model.\"\"\"\n",
        "    inputs = layers.Input(shape=input_shape)  # Input layer with the specified shape\n",
        "\n",
        "    # Patch embedding\n",
        "    patch_size = 16  # Size of each image patch\n",
        "    num_patches = (input_shape[0] // patch_size) * (input_shape[1] // patch_size)  # Calculate total number of patches\n",
        "    patches = layers.Conv2D(filters=64, kernel_size=patch_size, strides=patch_size, padding='valid')(inputs)  # Extract patches\n",
        "    patches = layers.Reshape((num_patches, -1))(patches)  # Reshape patches into 2D array for transformer\n",
        "\n",
        "    # Positional embedding\n",
        "    positional_embedding = layers.Embedding(input_dim=num_patches, output_dim=64)(tf.range(num_patches))  # Add positional info\n",
        "    x = patches + positional_embedding  # Add positional embeddings to the patch embeddings\n",
        "\n",
        "    # Transformer encoder layers\n",
        "    for _ in range(8):  # Add 8 transformer encoder layers\n",
        "        # Multi-head self-attention\n",
        "        attention_output = layers.MultiHeadAttention(num_heads=4, key_dim=64)(x, x)  # Apply attention mechanism\n",
        "        x = layers.Add()([x, attention_output])  # Add residual connection\n",
        "        x = layers.LayerNormalization()(x)  # Normalize the output\n",
        "\n",
        "        # Feed-forward network\n",
        "        ff_output = layers.Dense(128, activation='relu')(x)  # First dense layer with ReLU activation\n",
        "        ff_output = layers.Dense(64)(ff_output)  # Second dense layer without activation\n",
        "        x = layers.Add()([x, ff_output])  # Add residual connection\n",
        "        x = layers.LayerNormalization()(x)  # Normalize the output\n",
        "\n",
        "    # Classification head\n",
        "    x = layers.GlobalAveragePooling1D()(x)  # Global average pooling to reduce dimensions\n",
        "    outputs = layers.Dense(num_classes, activation='softmax')(x)  # Output layer with softmax activation\n",
        "\n",
        "    model = models.Model(inputs, outputs)  # Create the model\n",
        "    return model  # Return the model\n"
      ],
      "metadata": {
        "id": "sPmnh9ms5qF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the ViT model\n",
        "input_shape = (224, 224, 1)  # Input shape for grayscale images\n",
        "num_classes = len(class_names)  # Number of classes (tumor types + no tumor)\n",
        "model = create_vit_model(input_shape, num_classes)  # Build the model\n"
      ],
      "metadata": {
        "id": "yZNnLJUZ50In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])  # Compile with Adam optimizer\n",
        "\n",
        "# Step 3: Train the model\n",
        "history = model.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=20, batch_size=32)  # Train the model\n",
        "\n",
        "# Step 4: Evaluate the model\n",
        "predictions = model.predict(test_images)  # Predict on the test set\n",
        "predicted_labels = np.argmax(predictions, axis=1)  # Convert probabilities to class labels\n"
      ],
      "metadata": {
        "id": "LBe-Mo_vBG3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Classification report\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(test_labels, predicted_labels, target_names=class_names))  # Print detailed metrics\n",
        "\n",
        "# Confusion matrix\n",
        "cm = confusion_matrix(test_labels, predicted_labels)  # Compute confusion matrix\n",
        "plt.figure(figsize=(12, 10))  # Set figure size\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)  # Plot heatmap\n",
        "plt.xlabel('Predicted Labels')  # Label for x-axis\n",
        "plt.ylabel('True Labels')  # Label for y-axis\n",
        "plt.title('Confusion Matrix')  # Title of the plot\n",
        "plt.show()  # Display the plot\n",
        "\n",
        "# Step 5: Plot training and validation metrics\n",
        "def plot_metrics(history):\n",
        "    \"\"\"Plot accuracy and loss curves.\"\"\"\n",
        "    plt.figure(figsize=(12, 5))  # Set figure size\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 1)  # Create a subplot for accuracy\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')  # Plot training accuracy\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')  # Plot validation accuracy\n",
        "    plt.title('Accuracy Over Epochs')  # Title for accuracy plot\n",
        "    plt.xlabel('Epochs')  # Label for x-axis\n",
        "    plt.ylabel('Accuracy')  # Label for y-axis\n",
        "    plt.legend()  # Add legend\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 2)  # Create a subplot for loss\n",
        "    plt.plot(history.history['loss'], label='Training Loss')  # Plot training loss\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')  # Plot validation loss\n",
        "    plt.title('Loss Over Epochs')  # Title for loss plot\n",
        "    plt.xlabel('Epochs')  # Label for x-axis\n",
        "    plt.ylabel('Loss')  # Label for y-axis\n",
        "    plt.legend()  # Add legend\n",
        "\n",
        "    plt.show()  # Display the plots\n",
        "\n",
        "plot_metrics(history)  # Call the function to plot metrics\n"
      ],
      "metadata": {
        "id": "76JbPnX7_dHO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}