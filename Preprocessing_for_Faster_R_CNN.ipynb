{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1COvZtUnm5HGJ3s-IvN0l-47yFRcBOCaY",
      "authorship_tag": "ABX9TyN2zpiXYkqil+g+DQZIJSJ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classficiation-CNN/Preprocessing_for_Faster_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "_2DoiRAE3508"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless matplotlib pandas SimpleITK\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "import seaborn as sns\n",
        "import gc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mayb4_V037v3",
        "outputId": "894be9fe-85c8-49b8-af92-3c096693dec3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "NxoKmQJc4CRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27_zTs74EPi",
        "outputId": "22935dea-ef2b-41c9-c87d-25c022742691"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Folder Structure Setup"
      ],
      "metadata": {
        "id": "YiGAEEYA4HM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_zip_path = \"/content/drive/My Drive/DSGP/DSGP_Dataset.zip\"\n",
        "extracted_dataset_path = \"/content/original_dataset\"\n",
        "\n",
        "# Unzip dataset if not already extracted\n",
        "if not os.path.exists(extracted_dataset_path):\n",
        "    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_dataset_path)\n",
        "\n",
        "base_dir = '/content/drive/My Drive/DSGP/Preprocessed Dataset'\n",
        "\n",
        "# Create main folders\n",
        "folders = [\n",
        "    'Images/Train/Tumor',\n",
        "    'Images/Train/No_Tumor',\n",
        "    'Images/Val/Tumor',\n",
        "    'Images/Val/No_Tumor',\n",
        "    'Images/Test/Tumor',\n",
        "    'Images/Test/No_Tumor',\n",
        "    'Annotations/Train',\n",
        "    'Annotations/Val',\n",
        "    'Annotations/Test'\n",
        "]\n",
        "\n",
        "for folder in folders:\n",
        "    os.makedirs(os.path.join(base_dir, folder), exist_ok=True)"
      ],
      "metadata": {
        "id": "RN4kwr5I4LKn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Annotation Creation"
      ],
      "metadata": {
        "id": "iaxNOgWL4ZAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_tumor_bbox(img):\n",
        "    \"\"\"Automatically detect tumor region using intensity thresholding\"\"\"\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if contours:\n",
        "        largest = max(contours, key=cv2.contourArea)\n",
        "        x,y,w,h = cv2.boundingRect(largest)\n",
        "        return [x,y,x+w,y+h]\n",
        "    return [0,0,0,0]  # For non-tumor\n",
        "\n",
        "def create_xml(image_path, class_name, box, size):\n",
        "    root = ET.Element(\"annotation\")\n",
        "    ET.SubElement(root, \"filename\").text = os.path.basename(image_path)\n",
        "    size_elem = ET.SubElement(root, \"size\")\n",
        "    ET.SubElement(size_elem, \"width\").text = str(size[1])\n",
        "    ET.SubElement(size_elem, \"height\").text = str(size[0])\n",
        "    ET.SubElement(size_elem, \"depth\").text = \"3\"\n",
        "    obj = ET.SubElement(root, \"object\")\n",
        "    ET.SubElement(obj, \"name\").text = class_name\n",
        "    ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n",
        "    bndbox = ET.SubElement(obj, \"bndbox\")\n",
        "    ET.SubElement(bndbox, \"xmin\").text = str(box[0])\n",
        "    ET.SubElement(bndbox, \"ymin\").text = str(box[1])\n",
        "    ET.SubElement(bndbox, \"xmax\").text = str(box[2])\n",
        "    ET.SubElement(bndbox, \"ymax\").text = str(box[3])\n",
        "    xml_str = ET.tostring(root)\n",
        "    xml_pretty = minidom.parseString(xml_str).toprettyxml()\n",
        "    return xml_pretty"
      ],
      "metadata": {
        "id": "wm3sXniG4fBF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Functions"
      ],
      "metadata": {
        "id": "KVy8Hy754iCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Skull Stripping\n",
        "def skull_stripping(img):\n",
        "    sitk_img = sitk.GetImageFromArray(img)\n",
        "    sitk_img = sitk.Cast(sitk_img, sitk.sitkFloat32)\n",
        "    mask = sitk.OtsuThreshold(sitk_img, 0, 1, 200)\n",
        "    mask = sitk.BinaryMorphologicalClosing(mask, [3]*3)\n",
        "    return sitk.GetArrayFromImage(sitk.Mask(sitk_img, mask))"
      ],
      "metadata": {
        "id": "aHWuPPp54kbH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Normalization\n",
        "def normalize_image(img):\n",
        "    p2, p98 = np.percentile(img, (2, 98))\n",
        "    img = np.clip(img, p2, p98)\n",
        "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "bVB9qIjI4pdy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing Pipeline\n",
        "def preprocess_pipeline(img_path, target_size=(256, 256)):\n",
        "    img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n",
        "    skull_free = skull_stripping(img)\n",
        "    normalized = normalize_image(skull_free)\n",
        "    return cv2.resize(normalized, target_size)"
      ],
      "metadata": {
        "id": "mPKcdRTY4tve"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "V1CO9mpZ4znv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(img):\n",
        "    h,w = img.shape[:2]\n",
        "    center = (np.random.randint(w//4, 3*w//4),\n",
        "             np.random.randint(h//4, 3*h//4))\n",
        "    scale = np.random.uniform(0.9, 1.1)\n",
        "\n",
        "    M = cv2.getRotationMatrix2D(center, np.random.randint(-15,15), scale)\n",
        "    return cv2.warpAffine(img, M, (w,h))"
      ],
      "metadata": {
        "id": "qjxttOy342Ph"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot Image Distribution"
      ],
      "metadata": {
        "id": "oPcSpUvQrXB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_distribution(df):\n",
        "    class_counts = df['class'].value_counts()\n",
        "    print(\"Image Count Before Balancing:\")\n",
        "    print(class_counts)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.barplot(x=class_counts.index, y=class_counts.values, palette=['red', 'blue'])\n",
        "    plt.xlabel(\"Class\")\n",
        "    plt.ylabel(\"Image Count\")\n",
        "    plt.title(\"Tumor vs No-Tumor Image Distribution Before Balancing\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "821aQ6KZrZFu"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Function"
      ],
      "metadata": {
        "id": "BMZXlhys49LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset():\n",
        "    data = []\n",
        "    # Collect data with proper class naming\n",
        "    for folder_name in ['no tumour', 'tumour']:  # Original folder names with space\n",
        "        class_path = os.path.join(extracted_dataset_path, folder_name)\n",
        "        class_label = 'No_Tumor' if 'no ' in folder_name else 'Tumor'  # Standardized labels\n",
        "\n",
        "        for root, _, files in os.walk(class_path):\n",
        "            for file in files:\n",
        "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    data.append({\n",
        "                        'path': os.path.join(root, file),\n",
        "                        'class': class_label  # Use standardized label\n",
        "                    })\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "    plot_image_distribution(df)\n",
        "\n",
        "    # Class balancing with standardized labels\n",
        "    tumor_df = df[df['class'] == 'Tumor']\n",
        "    no_tumor_df = df[df['class'] == 'No_Tumor']\n",
        "\n",
        "    if len(tumor_df) < len(no_tumor_df):\n",
        "        tumor_df = tumor_df.sample(len(no_tumor_df), replace=True)\n",
        "    else:\n",
        "        no_tumor_df = no_tumor_df.sample(len(tumor_df), replace=True)\n",
        "\n",
        "    balanced_df = pd.concat([tumor_df, no_tumor_df])\n",
        "\n",
        "    # Data splitting\n",
        "    train_df, temp_df = train_test_split(balanced_df, test_size=0.3, stratify=balanced_df['class'])\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['class'])\n",
        "\n",
        "    # Processing loop\n",
        "    sample_shown = False\n",
        "    for split_df, split_name in zip([train_df, val_df, test_df], ['Train', 'Val', 'Test']):\n",
        "        for idx, row in split_df.iterrows():\n",
        "            try:\n",
        "                # Preprocess image\n",
        "                processed_img = preprocess_pipeline(row['path'])\n",
        "\n",
        "                # Augment only tumor training images\n",
        "                if row['class'] == 'Tumor' and split_name == 'Train':\n",
        "                    processed_img = augment_image(processed_img)\n",
        "\n",
        "                # Save image with consistent folder names\n",
        "                img_filename = f\"{split_name.lower()}_{idx}.png\"\n",
        "                img_save_path = f\"{base_dir}/Images/{split_name}/{row['class']}/{img_filename}\"\n",
        "                cv2.imwrite(img_save_path, cv2.cvtColor(processed_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "                # Generate bounding boxes\n",
        "                bbox = find_tumor_bbox(processed_img) if row['class'] == 'Tumor' else [0,0,0,0]\n",
        "\n",
        "                # Create XML with standardized class names\n",
        "                xml_content = create_xml(img_filename, row['class'], bbox, processed_img.shape)\n",
        "                xml_save_path = f\"{base_dir}/Annotations/{split_name}/{img_filename.split('.')[0]}.xml\"\n",
        "                with open(xml_save_path, 'w') as f:\n",
        "                    f.write(xml_content)\n",
        "\n",
        "                # Show first sample\n",
        "                if not sample_shown and idx == 0:\n",
        "                    show_annotation(img_save_path, xml_save_path)\n",
        "                    sample_shown = True\n",
        "\n",
        "                # Memory management\n",
        "                if idx % 50 == 0:\n",
        "                    gc.collect()\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {row['path']}: {str(e)}\")\n",
        "\n",
        "    # Final validation\n",
        "    required_folders = ['Images/Train/Tumor', 'Annotations/Train']\n",
        "    for folder in required_folders:\n",
        "        if not os.path.exists(f\"{base_dir}/{folder}\"):\n",
        "            raise FileNotFoundError(f\"Critical folder missing: {folder}\")"
      ],
      "metadata": {
        "id": "LAfpXlQH5Cra"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Preprocessing"
      ],
      "metadata": {
        "id": "PuOwoT_i5Djx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_dataset()\n",
        "print(\"Preprocessing complete! All files saved in:\", base_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 668
        },
        "id": "RzyodI0N5GXH",
        "outputId": "018e5fce-425c-49ee-edbe-8013636445ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'class'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-d87988f21460>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Preprocessing complete! All files saved in:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-7ce1a82a3c14>\u001b[0m in \u001b[0;36mprocess_dataset\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mplot_image_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Class balancing with standardized labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-8f23ac7e2b49>\u001b[0m in \u001b[0;36mplot_image_distribution\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_image_distribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mclass_counts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image Count Before Balancing:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_counts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/range.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    415\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHashable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_indexing_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'class'"
          ]
        }
      ]
    }
  ]
}