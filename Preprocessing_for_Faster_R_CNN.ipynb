{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classficiation-CNN/Preprocessing_for_Faster_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2DoiRAE3508"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mayb4_V037v3",
        "outputId": "590a872d-f260-46bb-cac4-6e9ffb73e4e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Collecting SimpleITK\n",
            "  Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Downloading SimpleITK-2.4.1-cp311-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (52.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m52.3/52.3 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: SimpleITK\n",
            "Successfully installed SimpleITK-2.4.1\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python-headless matplotlib pandas SimpleITK\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "import SimpleITK as sitk\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxoKmQJc4CRe"
      },
      "source": [
        "Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27_zTs74EPi",
        "outputId": "d40bc652-ce9c-45dd-d37c-c4ae65f6354d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiGAEEYA4HM8"
      },
      "source": [
        "Folder Structure Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RN4kwr5I4LKn"
      },
      "outputs": [],
      "source": [
        "# Paths\n",
        "extracted_dataset_path = \"/content/drive/MyDrive/DSGP/DSGP_dataset\"\n",
        "base_dir = \"/content/drive/MyDrive/DSGP/Preprocessed Dataset\"\n",
        "\n",
        "# Ensure extracted dataset contains files before proceeding\n",
        "if not os.path.exists(extracted_dataset_path) or not any(os.scandir(extracted_dataset_path)):\n",
        "    raise RuntimeError(f\"Error: Extracted dataset is missing or empty at {extracted_dataset_path}\")\n",
        "\n",
        "# Create required folder structure\n",
        "folders = [\n",
        "    'Images/Train', 'Images/Val', 'Images/Test',\n",
        "    'Annotations/Train', 'Annotations/Val', 'Annotations/Test'\n",
        "]\n",
        "for folder in folders:\n",
        "    os.makedirs(os.path.join(base_dir, folder), exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaxNOgWL4ZAi"
      },
      "source": [
        "Annotation Creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "wm3sXniG4fBF"
      },
      "outputs": [],
      "source": [
        "def create_xml(image_path, class_name, box, size):\n",
        "    root = ET.Element(\"annotation\")\n",
        "    ET.SubElement(root, \"filename\").text = os.path.basename(image_path)\n",
        "    size_elem = ET.SubElement(root, \"size\")\n",
        "    ET.SubElement(size_elem, \"width\").text = str(size[1])\n",
        "    ET.SubElement(size_elem, \"height\").text = str(size[0])\n",
        "    ET.SubElement(size_elem, \"depth\").text = \"3\"\n",
        "    obj = ET.SubElement(root, \"object\")\n",
        "    ET.SubElement(obj, \"name\").text = class_name\n",
        "    ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n",
        "    bndbox = ET.SubElement(obj, \"bndbox\")\n",
        "    ET.SubElement(bndbox, \"xmin\").text = str(box[0])\n",
        "    ET.SubElement(bndbox, \"ymin\").text = str(box[1])\n",
        "    ET.SubElement(bndbox, \"xmax\").text = str(box[2])\n",
        "    ET.SubElement(bndbox, \"ymax\").text = str(box[3])\n",
        "    return minidom.parseString(ET.tostring(root)).toprettyxml()\n",
        "\n",
        "# Find Tumor Bounding Box\n",
        "def find_tumor_bbox(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        x, y, w, h = cv2.boundingRect(max(contours, key=cv2.contourArea))\n",
        "        return [x, y, x + w, y + h]\n",
        "    return [0, 0, 0, 0]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVy8Hy754iCg"
      },
      "source": [
        "Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "aHWuPPp54kbH"
      },
      "outputs": [],
      "source": [
        "# Skull Stripping\n",
        "def skull_stripping(img):\n",
        "    sitk_img = sitk.GetImageFromArray(img)\n",
        "    sitk_img = sitk.Cast(sitk_img, sitk.sitkFloat32)\n",
        "    mask = sitk.OtsuThreshold(sitk_img)\n",
        "    stripped_img = sitk.GetArrayFromImage(sitk.Mask(sitk_img, mask))\n",
        "    return cv2.normalize(stripped_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bVB9qIjI4pdy"
      },
      "outputs": [],
      "source": [
        "def normalize_image(img):\n",
        "    p2, p98 = np.percentile(img, (2, 98))\n",
        "    img = np.clip(img, p2, p98)\n",
        "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mPKcdRTY4tve"
      },
      "outputs": [],
      "source": [
        "def preprocess_pipeline(img_path, target_size=(256, 256)):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Warning: Could not read image {img_path}. Skipping...\")\n",
        "        return None\n",
        "\n",
        "    if img.dtype == np.float64:\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    if len(img.shape) == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    skull_free = skull_stripping(img)\n",
        "    normalized = normalize_image(skull_free)\n",
        "\n",
        "    final_img = (normalized * 255).astype(np.uint8)\n",
        "    return cv2.resize(final_img, target_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1CO9mpZ4znv"
      },
      "source": [
        "Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "qjxttOy342Ph"
      },
      "outputs": [],
      "source": [
        "def augment_image(img):\n",
        "    h, w = img.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((w//2, h//2), np.random.randint(-15, 15), np.random.uniform(0.9, 1.1))\n",
        "    return cv2.warpAffine(img, M, (w, h))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMZXlhys49LY"
      },
      "source": [
        "Preprocessing Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "LAfpXlQH5Cra"
      },
      "outputs": [],
      "source": [
        "def process_dataset():\n",
        "    data = []\n",
        "    for root, dirs, files in os.walk(extracted_dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                class_label = os.path.basename(root)\n",
        "                if \"no tumor\" in class_label.lower():\n",
        "                    class_label = \"No_Tumor\"\n",
        "                data.append({\"path\": os.path.join(root, file), \"class\": class_label})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    if df.empty:\n",
        "        raise RuntimeError(\"Error: No images found in the dataset!\")\n",
        "\n",
        "    print(\"Class distribution before balancing:\\n\", df['class'].value_counts())\n",
        "\n",
        "    # Class Balancing\n",
        "    min_samples = df['class'].value_counts().max()\n",
        "    balanced_df = df.groupby('class', group_keys=False).apply(lambda x: x.sample(min_samples, replace=True)).reset_index(drop=True)\n",
        "\n",
        "    print(\"Class distribution after balancing:\\n\", balanced_df['class'].value_counts())\n",
        "\n",
        "    # Splitting\n",
        "    train_df, temp_df = train_test_split(balanced_df, test_size=0.3, stratify=balanced_df['class'])\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['class'])\n",
        "\n",
        "    # Processing\n",
        "    for split_df, split_name in zip([train_df, val_df, test_df], ['Train', 'Val', 'Test']):\n",
        "        for idx, row in split_df.iterrows():\n",
        "            processed_img = preprocess_pipeline(row['path'])\n",
        "            if processed_img is None:\n",
        "                continue\n",
        "\n",
        "            if row['class'] != \"No_Tumor\" and split_name == \"Train\":\n",
        "                processed_img = augment_image(processed_img)\n",
        "\n",
        "            img_filename = f\"{split_name.lower()}_{idx}.png\"\n",
        "            class_folder = f\"{base_dir}/Images/{split_name}/{row['class']}\"\n",
        "            os.makedirs(class_folder, exist_ok=True)\n",
        "            cv2.imwrite(os.path.join(class_folder, img_filename), cv2.cvtColor(processed_img, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "            # üîπ Ensure annotations are created\n",
        "            annotation_folder = f\"{base_dir}/Annotations/{split_name}/{row['class']}\"\n",
        "            os.makedirs(annotation_folder, exist_ok=True)\n",
        "            bbox = find_tumor_bbox(processed_img) if row['class'] != \"No_Tumor\" else [0, 0, 0, 0]\n",
        "            with open(f\"{annotation_folder}/{img_filename.split('.')[0]}.xml\", 'w') as f:\n",
        "                f.write(create_xml(img_filename, row['class'], bbox, processed_img.shape))\n",
        "\n",
        "    print(\"Preprocessing complete! All files saved in:\", base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuOwoT_i5Djx"
      },
      "source": [
        "Run Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzyodI0N5GXH",
        "outputId": "ae7b047d-a48d-4884-da20-9149a20372a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before balancing:\n",
            " class\n",
            "no tumour            2000\n",
            "pituitary            1757\n",
            "meningioma           1645\n",
            "Astrocitoma           574\n",
            "Neurocitoma           457\n",
            "Schwannoma            453\n",
            "Papiloma              227\n",
            "Oligodendroglioma     220\n",
            "Glioblastoma          197\n",
            "Carcinoma             186\n",
            "Ependimoma            150\n",
            "Tuberculoma           138\n",
            "Meduloblastoma        126\n",
            "Germinoma              97\n",
            "Granuloma              78\n",
            "Ganglioglioma          59\n",
            "Name: count, dtype: int64\n",
            "Class distribution after balancing:\n",
            " class\n",
            "Astrocitoma          2000\n",
            "Carcinoma            2000\n",
            "Ependimoma           2000\n",
            "Ganglioglioma        2000\n",
            "Germinoma            2000\n",
            "Glioblastoma         2000\n",
            "Granuloma            2000\n",
            "Meduloblastoma       2000\n",
            "Neurocitoma          2000\n",
            "Oligodendroglioma    2000\n",
            "Papiloma             2000\n",
            "Schwannoma           2000\n",
            "Tuberculoma          2000\n",
            "meningioma           2000\n",
            "no tumour            2000\n",
            "pituitary            2000\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-eed689183e16>:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  balanced_df = df.groupby('class', group_keys=False).apply(lambda x: x.sample(min_samples, replace=True)).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete! All files saved in: /content/drive/MyDrive/DSGP/Preprocessed Dataset\n",
            "Preprocessing complete! All files saved in: /content/drive/MyDrive/DSGP/Preprocessed Dataset\n"
          ]
        }
      ],
      "source": [
        "process_dataset()\n",
        "print(\"Preprocessing complete! All files saved in:\", base_dir)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "mount_file_id": "1COvZtUnm5HGJ3s-IvN0l-47yFRcBOCaY",
      "authorship_tag": "ABX9TyN44zDmkRLs7fWVoTgz6bsK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}