{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1COvZtUnm5HGJ3s-IvN0l-47yFRcBOCaY",
      "authorship_tag": "ABX9TyM1KbZMsWSR6/f/HE38GSyF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TharinsaMudalige/Neuron-Brain_Tumor_Detection_Classification_with_XAI/blob/Detection-Classficiation-CNN/Preprocessing_for_Faster_R_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Libraries"
      ],
      "metadata": {
        "id": "_2DoiRAE3508"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opencv-python-headless matplotlib pandas SimpleITK\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "from xml.dom import minidom\n",
        "import matplotlib.pyplot as plt\n",
        "import SimpleITK as sitk\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "import zipfile\n",
        "import gc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mayb4_V037v3",
        "outputId": "cf29b716-9851-4a81-c5af-259f6aa80fa4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: SimpleITK in /usr/local/lib/python3.11/dist-packages (2.4.1)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python-headless) (1.26.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive"
      ],
      "metadata": {
        "id": "NxoKmQJc4CRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c27_zTs74EPi",
        "outputId": "62f48b8f-bc8c-4ea5-b9bb-08903453bed8"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Folder Structure Setup"
      ],
      "metadata": {
        "id": "YiGAEEYA4HM8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths\n",
        "extracted_dataset_path = \"/content/drive/MyDrive/DSGP/DSGP_dataset\"\n",
        "base_dir = \"/content/drive/MyDrive/DSGP/Preprocessed Dataset\"\n",
        "\n",
        "# Unzip dataset if not already extracted\n",
        "if not os.path.exists(extracted_dataset_path):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extracted_dataset_path)\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n",
        "\n",
        "# Ensure extracted dataset contains files before proceeding\n",
        "if not any(os.scandir(extracted_dataset_path)):\n",
        "    raise RuntimeError(f\"Error: Extracted dataset is empty at {extracted_dataset_path}\")\n",
        "\n",
        "# Create required folder structure\n",
        "folders = [\n",
        "    'Images/Train', 'Images/Val', 'Images/Test',\n",
        "    'Annotations/Train', 'Annotations/Val', 'Annotations/Test'\n",
        "]\n",
        "for folder in folders:\n",
        "    os.makedirs(os.path.join(base_dir, folder), exist_ok=True)"
      ],
      "metadata": {
        "id": "RN4kwr5I4LKn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42787e85-1c19-42a3-b938-ab8ce5ae4d64"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already extracted.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Annotation Creation"
      ],
      "metadata": {
        "id": "iaxNOgWL4ZAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_xml(image_path, class_name, box, size):\n",
        "    root = ET.Element(\"annotation\")\n",
        "    ET.SubElement(root, \"filename\").text = os.path.basename(image_path)\n",
        "    size_elem = ET.SubElement(root, \"size\")\n",
        "    ET.SubElement(size_elem, \"width\").text = str(size[1])\n",
        "    ET.SubElement(size_elem, \"height\").text = str(size[0])\n",
        "    ET.SubElement(size_elem, \"depth\").text = \"3\"\n",
        "    obj = ET.SubElement(root, \"object\")\n",
        "    ET.SubElement(obj, \"name\").text = class_name\n",
        "    ET.SubElement(obj, \"pose\").text = \"Unspecified\"\n",
        "    bndbox = ET.SubElement(obj, \"bndbox\")\n",
        "    ET.SubElement(bndbox, \"xmin\").text = str(box[0])\n",
        "    ET.SubElement(bndbox, \"ymin\").text = str(box[1])\n",
        "    ET.SubElement(bndbox, \"xmax\").text = str(box[2])\n",
        "    ET.SubElement(bndbox, \"ymax\").text = str(box[3])\n",
        "    return minidom.parseString(ET.tostring(root)).toprettyxml()\n",
        "\n",
        "def find_tumor_bbox(img):\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU)\n",
        "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        largest = max(contours, key=cv2.contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(largest)\n",
        "        return [x, y, x + w, y + h]\n",
        "    return [0, 0, 0, 0]\n"
      ],
      "metadata": {
        "id": "wm3sXniG4fBF"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Functions"
      ],
      "metadata": {
        "id": "KVy8Hy754iCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Skull Stripping\n",
        "def skull_stripping(img):\n",
        "    sitk_img = sitk.GetImageFromArray(img)\n",
        "    sitk_img = sitk.Cast(sitk_img, sitk.sitkFloat32)\n",
        "    mask = sitk.OtsuThreshold(sitk_img)\n",
        "    stripped_img = sitk.GetArrayFromImage(sitk.Mask(sitk_img, mask))\n",
        "    return cv2.normalize(stripped_img, None, 0, 255, cv2.NORM_MINMAX).astype(np.uint8)"
      ],
      "metadata": {
        "id": "aHWuPPp54kbH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_image(img):\n",
        "    p2, p98 = np.percentile(img, (2, 98))\n",
        "    img = np.clip(img, p2, p98)\n",
        "    return cv2.normalize(img, None, 0, 255, cv2.NORM_MINMAX)"
      ],
      "metadata": {
        "id": "bVB9qIjI4pdy"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_pipeline(img_path, target_size=(256, 256)):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Warning: Could not read image {img_path}. Skipping...\")\n",
        "        return None\n",
        "\n",
        "    if img.dtype == np.float64:\n",
        "        img = (img * 255).astype(np.uint8)\n",
        "\n",
        "    if len(img.shape) == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    else:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    skull_free = skull_stripping(img)\n",
        "    normalized = normalize_image(skull_free)\n",
        "\n",
        "    final_img = (normalized * 255).astype(np.uint8)\n",
        "    return cv2.resize(final_img, target_size)"
      ],
      "metadata": {
        "id": "mPKcdRTY4tve"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Augmentation"
      ],
      "metadata": {
        "id": "V1CO9mpZ4znv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_image(img):\n",
        "    h, w = img.shape[:2]\n",
        "    M = cv2.getRotationMatrix2D((w//2, h//2), np.random.randint(-15, 15), np.random.uniform(0.9, 1.1))\n",
        "    return cv2.warpAffine(img, M, (w, h))"
      ],
      "metadata": {
        "id": "qjxttOy342Ph"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing Function"
      ],
      "metadata": {
        "id": "BMZXlhys49LY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_dataset():\n",
        "    data = []\n",
        "    for root, dirs, files in os.walk(extracted_dataset_path):\n",
        "        for file in files:\n",
        "            if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                class_label = os.path.basename(root)\n",
        "                if \"no tumor\" in class_label.lower():\n",
        "                    class_label = \"No_Tumor\"\n",
        "                data.append({\"path\": os.path.join(root, file), \"class\": class_label})\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Class Balancing (Upsampling)\n",
        "    min_samples = max(df['class'].value_counts())  # Balance by increasing small classes\n",
        "    balanced_df = df.groupby('class', group_keys=False, observed=True).apply(lambda x: x.sample(min_samples, replace=True)).reset_index(drop=True)\n",
        "\n",
        "    # Splitting\n",
        "    train_df, temp_df = train_test_split(balanced_df, test_size=0.3, stratify=balanced_df['class'])\n",
        "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['class'])\n",
        "\n",
        "    # Processing\n",
        "    for split_df, split_name in zip([train_df, val_df, test_df], ['Train', 'Val', 'Test']):\n",
        "        for idx, row in split_df.iterrows():\n",
        "            processed_img = preprocess_pipeline(row['path'])\n",
        "            if processed_img is None:\n",
        "                continue\n",
        "\n",
        "            if row['class'] != \"No_Tumor\" and split_name == \"Train\":\n",
        "                processed_img = augment_image(processed_img)\n",
        "\n",
        "            img_filename = f\"{split_name.lower()}_{idx}.png\"\n",
        "            class_folder = f\"{base_dir}/Images/{split_name}/{row['class']}\"\n",
        "            os.makedirs(class_folder, exist_ok=True)\n",
        "            cv2.imwrite(os.path.join(class_folder, img_filename), cv2.cvtColor(processed_img, cv2.COLOR_RGB2BGR))"
      ],
      "metadata": {
        "id": "LAfpXlQH5Cra"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run Preprocessing"
      ],
      "metadata": {
        "id": "PuOwoT_i5Djx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "process_dataset()\n",
        "print(\"Preprocessing complete! All files saved in:\", base_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzyodI0N5GXH",
        "outputId": "463943e4-9eb2-434a-ecdf-c31cc598d314"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-77a6861c71b8>:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  balanced_df = df.groupby('class', group_keys=False, observed=True).apply(lambda x: x.sample(min_samples, replace=True)).reset_index(drop=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessing complete! All files saved in: /content/drive/MyDrive/DSGP/Preprocessed Dataset\n"
          ]
        }
      ]
    }
  ]
}